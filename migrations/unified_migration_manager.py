import os
import sys
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Callable
from datetime import datetime
from alembic.config import Config
from alembic import command
from scripts.tools.data_migrator import DataMigrator


class UnifiedMigrationManager:
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –º–∏–≥—Ä–∞—Ü–∏–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π:
    1. –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏ (Alembic) ‚Äî –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ö–µ–º—ã –ë–î
    2. –ú–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö (—Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫) ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å-–¥–∞–Ω–Ω—ã—Ö

    –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ —Å –µ–¥–∏–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.
    """

    def __init__(self, alembic_cfg_path: str = "migrations/alembic.ini"):
        self.alembic_cfg = Config(alembic_cfg_path)
        self.data_migrator = DataMigrator()
        self.migration_log_path = Path("data/migrations/migration_log.json")
        self.migration_log_path.parent.mkdir(parents=True, exist_ok=True)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–∞ –º–∏–≥—Ä–∞—Ü–∏–π, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not self.migration_log_path.exists():
            with open(self.migration_log_path, 'w') as f:
                json.dump({"applied_migrations": [], "data_migrations": []}, f, indent=2)

    def _load_migration_log(self) -> Dict:
        with open(self.migration_log_path) as f:
            return json.load(f)

    def _save_migration_log(self, log: Dict):
        with open(self.migration_log_path, 'w') as f:
            json.dump(log, f, indent=2)

    def upgrade_schema(self, revision: str = "head", sql: bool = False) -> List[str]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π —á–µ—Ä–µ–∑ Alembic.
        """
        print(f"üöÄ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π –¥–æ —Ä–µ–≤–∏–∑–∏–∏: {revision}")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º—ã—Ö —Ä–µ–≤–∏–∑–∏–π
        current_rev = command.current(self.alembic_cfg, silent=True)
        history = command.history(self.alembic_cfg, indicate_current=True)

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        command.upgrade(self.alembic_cfg, revision, sql=sql)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        new_rev = command.current(self.alembic_cfg, silent=True)
        log = self._load_migration_log()

        migration_record = {
            "type": "schema",
            "from_revision": str(current_rev),
            "to_revision": str(new_rev),
            "applied_at": datetime.utcnow().isoformat(),
            "sql_mode": sql,
            "hash": hashlib.sha256(f"{current_rev}->{new_rev}".encode()).hexdigest()
        }

        log["applied_migrations"].append(migration_record)
        self._save_migration_log(log)

        print(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã: {current_rev} ‚Üí {new_rev}")
        return [str(new_rev)]

    def downgrade_schema(self, revision: str, sql: bool = False) -> List[str]:
        """
        –û—Ç–∫–∞—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π —á–µ—Ä–µ–∑ Alembic.
        """
        print(f"‚è™ –û—Ç–∫–∞—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π –¥–æ —Ä–µ–≤–∏–∑–∏–∏: {revision}")

        current_rev = command.current(self.alembic_cfg, silent=True)
        command.downgrade(self.alembic_cfg, revision, sql=sql)
        new_rev = command.current(self.alembic_cfg, silent=True)

        log = self._load_migration_log()
        log["applied_migrations"].append({
            "type": "schema_downgrade",
            "from_revision": str(current_rev),
            "to_revision": str(new_rev),
            "applied_at": datetime.utcnow().isoformat(),
            "sql_mode": sql
        })
        self._save_migration_log(log)

        print(f"‚úÖ –û—Ç–∫–∞—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω: {current_rev} ‚Üí {new_rev}")
        return [str(new_rev)]

    def run_data_migration(self, migration_name: str, batch_size: int = 1000) -> Dict:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ—Ç–∫–∞—Ç–∞.

        –ü—Ä–∏–º–µ—Ä—ã –º–∏–≥—Ä–∞—Ü–∏–π:
        - convert_old_job_format ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –∑–∞–∫–∞–∑–æ–≤
        - backfill_client_preferences ‚Üí –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤
        - anonymize_old_data ‚Üí –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è GDPR
        """
        print(f"üìä –ó–∞–ø—É—Å–∫ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {migration_name}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏
        migration_func = getattr(self.data_migrator, f"migrate_{migration_name}", None)
        if not migration_func or not callable(migration_func):
            raise ValueError(f"–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö '{migration_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ—á–∫–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π
        backup_path = self._create_migration_backup(migration_name)

        try:
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
            total_records = self.data_migrator.get_total_records(migration_name)
            processed = 0

            while processed < total_records:
                batch = min(batch_size, total_records - processed)
                result = migration_func(batch_size=batch, offset=processed)

                processed += batch
                progress = (processed / total_records) * 100
                print(f"   üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({processed}/{total_records})")

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏
            log = self._load_migration_log()
            log["data_migrations"].append({
                "name": migration_name,
                "applied_at": datetime.utcnow().isoformat(),
                "records_processed": total_records,
                "backup_path": str(backup_path),
                "status": "completed"
            })
            self._save_migration_log(log)

            print(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö '{migration_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            return {"status": "success", "records_processed": total_records, "backup": str(backup_path)}

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            print(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {backup_path}")

            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–∫–∞—Ç
            self._restore_from_backup(backup_path)

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—É–¥–∞—á–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏
            log = self._load_migration_log()
            log["data_migrations"].append({
                "name": migration_name,
                "applied_at": datetime.utcnow().isoformat(),
                "error": str(e),
                "backup_path": str(backup_path),
                "status": "failed_rolled_back"
            })
            self._save_migration_log(log)

            raise RuntimeError(f"–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç–º–µ–Ω–µ–Ω–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {e}")

    def _create_migration_backup(self, migration_name: str) -> Path:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ—á–µ—á–Ω–æ–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö.
        """
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        backup_dir = Path(f"backup/migration_backups/{migration_name}_{timestamp}")
        backup_dir.mkdir(parents=True, exist_ok=True)

        # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        import shutil

        # –ó–∞–∫–∞–∑—ã
        if Path("data/jobs").exists():
            shutil.copytree("data/jobs", backup_dir / "jobs", dirs_exist_ok=True)

        # –ö–ª–∏–µ–Ω—Ç—ã
        if Path("data/clients").exists():
            shutil.copytree("data/clients", backup_dir / "clients", dirs_exist_ok=True)

        # –§–∏–Ω–∞–Ω—Å—ã
        if Path("data/finances").exists():
            shutil.copytree("data/finances", backup_dir / "finances", dirs_exist_ok=True)

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        with open(backup_dir / "migration_metadata.json", 'w') as f:
            json.dump({
                "migration_name": migration_name,
                "created_at": datetime.utcnow().isoformat(),
                "system_version": self._get_system_version(),
                "python_version": sys.version
            }, f, indent=2)

        print(f"üíæ –°–æ–∑–¥–∞–Ω–∞ —Ç–æ—á–µ—á–Ω–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_dir}")
        return backup_dir

    def _restore_from_backup(self, backup_path: Path):
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –ø–æ—Å–ª–µ –Ω–µ—É–¥–∞—á–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏.
        """
        import shutil

        print(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {backup_path}")

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–∫–∞–∑–æ–≤
        if (backup_path / "jobs").exists():
            shutil.rmtree("data/jobs", ignore_errors=True)
            shutil.copytree(backup_path / "jobs", "data/jobs")

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤
        if (backup_path / "clients").exists():
            shutil.rmtree("data/clients", ignore_errors=True)
            shutil.copytree(backup_path / "clients", "data/clients")

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤
        if (backup_path / "finances").exists():
            shutil.rmtree("data/finances", ignore_errors=True)
            shutil.copytree(backup_path / "finances", "data/finances")

        print("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

    def _get_system_version(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ —Å–∏—Å—Ç–µ–º—ã –∏–∑ pyproject.toml"""
        try:
            import tomli
            with open("pyproject.toml", "rb") as f:
                pyproject = tomli.load(f)
            return pyproject["tool"]["poetry"]["version"]
        except:
            return "unknown"

    def list_pending_migrations(self) -> Dict[str, List]:
        """
        –°–ø–∏—Å–æ–∫ –æ–∂–∏–¥–∞—é—â–∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–π (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –∏ –¥–∞–Ω–Ω—ã—Ö).
        """
        # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        command.history(self.alembic_cfg, indicate_current=True)
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ –≤—ã–≤–æ–¥–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è pending revisions

        # –î–∞–Ω–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏ ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        data_migrations_dir = Path("migrations/data_migrations")
        available = []
        if data_migrations_dir.exists():
            for file in data_migrations_dir.glob("*.py"):
                if file.stem not in ["__init__", "base_migration"]:
                    available.append(file.stem)

        log = self._load_migration_log()
        applied = [m["name"] for m in log.get("data_migrations", []) if m["status"] == "completed"]
        pending = [m for m in available if m not in applied]

        return {
            "schema_pending": ["—Ä–µ–≤–∏–∑–∏—è_005", "—Ä–µ–≤–∏–∑–∏—è_006"],  # –ü—Ä–∏–º–µ—Ä
            "data_pending": pending,
            "last_applied_schema": log["applied_migrations"][-1]["to_revision"] if log["applied_migrations"] else None,
            "last_applied_data": log["data_migrations"][-1]["name"] if log["data_migrations"] else None
        }

    def run_all_migrations(self, with_data: bool = True) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω –≤—Å–µ—Ö –º–∏–≥—Ä–∞—Ü–∏–π (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö + –¥–∞–Ω–Ω—ã—Ö) –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.
        """
        print("üèÅ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –º–∏–≥—Ä–∞—Ü–∏–π...")

        # 1. –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        schema_revs = self.upgrade_schema("head")

        # 2. –ú–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        data_results = []
        if with_data:
            pending = self.list_pending_migrations()["data_pending"]
            for migration_name in pending:
                try:
                    result = self.run_data_migration(migration_name)
                    data_results.append({migration_name: result})
                except Exception as e:
                    print(f"‚ö†Ô∏è  –ú–∏–≥—Ä–∞—Ü–∏—è {migration_name} –ø—Ä–æ–ø—É—â–µ–Ω–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {e}")
                    data_results.append({migration_name: {"status": "skipped", "error": str(e)}})

        print("üéâ –í—Å–µ –º–∏–≥—Ä–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã!")
        return {
            "schema_migrations": schema_revs,
            "data_migrations": data_results,
            "completed_at": datetime.utcnow().isoformat()
        }


# CLI-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏—è–º–∏
def migration_cli():
    import argparse

    parser = argparse.ArgumentParser(description="–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –º–∏–≥—Ä–∞—Ü–∏–π")
    parser.add_argument("action", choices=["upgrade", "downgrade", "list", "run-data", "run-all"],
                        help="–î–µ–π—Å—Ç–≤–∏–µ –Ω–∞–¥ –º–∏–≥—Ä–∞—Ü–∏—è–º–∏")
    parser.add_argument("--revision", default="head", help="–¶–µ–ª–µ–≤–∞—è —Ä–µ–≤–∏–∑–∏—è (–¥–ª—è downgrade/upgrade)")
    parser.add_argument("--migration-name", help="–ò–º—è –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è run-data)")
    parser.add_argument("--sql", action="store_true", help="–í—ã–≤–µ—Å—Ç–∏ SQL –±–µ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
    parser.add_argument("--batch-size", type=int, default=1000, help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö")

    args = parser.parse_args()
    manager = UnifiedMigrationManager()

    if args.action == "upgrade":
        manager.upgrade_schema(args.revision, args.sql)

    elif args.action == "downgrade":
        manager.downgrade_schema(args.revision, args.sql)

    elif args.action == "list":
        pending = manager.list_pending_migrations()
        print("–û–∂–∏–¥–∞—é—â–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏:", pending["schema_pending"])
        print("–û–∂–∏–¥–∞—é—â–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö:", pending["data_pending"])

    elif args.action == "run-data":
        if not args.migration_name:
            raise ValueError("--migration-name –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è run-data")
        manager.run_data_migration(args.migration_name, args.batch_size)

    elif args.action == "run-all":
        manager.run_all_migrations(with_data=True)


if __name__ == "__main__":
    migration_cli()
