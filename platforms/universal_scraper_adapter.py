"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ù–û–í–´–• –ø–ª–∞—Ç—Ñ–æ—Ä–º –±–µ–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ API
—á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–π —Å–∫—Ä–∞–ø–∏–Ω–≥ —Å –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã –æ—Ç –±–æ—Ç–æ–≤.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 50+ "—Å–µ—Ä—ã—Ö" –ø–ª–æ—â–∞–¥–æ–∫ –∏–∑ –°–ù–ì –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞.
"""

import json
import re
import time
import random
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
import hashlib
import base64

import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from core.security.encryption_engine import EncryptionEngine
from core.monitoring.alert_manager import AlertManager
from core.ai_management.ai_model_hub import get_ai_model_hub


class UniversalScraperAdapter:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º –∑–∞ 5 –º–∏–Ω—É—Ç.
    –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–∑–¥–∞—Ç—å YAML-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é ‚Äî –∫–æ–¥ —Å–∞–º –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –ø–æ–¥ –ª—é–±—É—é –ø–ª–æ—â–∞–¥–∫—É.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã –ø–ª–∞—Ç—Ñ–æ—Ä–º:
    - –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ HTML-—Å–∞–π—Ç—ã (—á–µ—Ä–µ–∑ BeautifulSoup)
    - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ SPA (—á–µ—Ä–µ–∑ Selenium)
    - –°–∞–π—Ç—ã —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –±–æ—Ç–æ–≤ (Cloudflare, hCaptcha)
    - –ú–æ–±–∏–ª—å–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ —Å–∞–π—Ç–æ–≤
    - Telegram-–∫–∞–Ω–∞–ª—ã —Å –∑–∞–∫–∞–∑–∞–º–∏ (—á–µ—Ä–µ–∑ API)
    """

    # –ë–∞–∑–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –¥–ª—è 50+ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–ª–æ—â–∞–¥–æ–∫ –°–ù–ì
    BUILT_IN_CONFIGS = {
        "youla_freelance": {
            "base_url": "https://youla.ru/moskva/uslugi",
            "search_pattern": "/moskva/uslugi?query={query}",
            "job_selector": ".product_item",
            "title_selector": ".product_item__title",
            "price_selector": ".product_item__price",
            "url_selector": "a.product_item__link",
            "requires_selenium": False,
            "anti_detection": True,
            "rate_limits": {"requests_per_minute": 5, "requests_per_hour": 50}
        },
        "avito_uslugi": {
            "base_url": "https://www.avito.ru",
            "search_pattern": "/moskva/uslugi?q={query}",
            "job_selector": "[data-marker='item']",
            "title_selector": "[itemprop='name']",
            "price_selector": "[itemprop='price']",
            "url_selector": "a[itemprop='url']",
            "requires_selenium": True,
            "anti_detection": True,
            "captcha_solver": "2captcha",
            "rate_limits": {"requests_per_minute": 3, "requests_per_hour": 30}
        },
        "irr_freelance": {
            "base_url": "https://irr.ru",
            "search_pattern": "/moscow/search/q-{query}/",
            "job_selector": ".listing__item",
            "title_selector": ".listing__item-title",
            "price_selector": ".listing__item-price",
            "url_selector": "a.listing__item-title-link",
            "requires_selenium": False,
            "anti_detection": True,
            "rate_limits": {"requests_per_minute": 6, "requests_per_hour": 60}
        },
        "workzilla": {
            "base_url": "https://workzilla.com",
            "search_pattern": "/freelancers/tasks?query={query}",
            "job_selector": ".task-item",
            "title_selector": ".task-title",
            "price_selector": ".task-price",
            "url_selector": "a.task-link",
            "requires_selenium": False,
            "anti_detection": False,
            "rate_limits": {"requests_per_minute": 10, "requests_per_hour": 100}
        },
        "weblancer": {
            "base_url": "https://www.weblancer.net",
            "search_pattern": "/jobs/?q={query}",
            "job_selector": ".task",
            "title_selector": ".title",
            "price_selector": ".amount",
            "url_selector": "a.title",
            "requires_selenium": False,
            "anti_detection": False,
            "rate_limits": {"requests_per_minute": 8, "requests_per_hour": 80}
        },
        "experts": {
            "base_url": "https://experts.ru",
            "search_pattern": "/projects/?q={query}",
            "job_selector": ".project-item",
            "title_selector": ".project-title",
            "price_selector": ".project-budget",
            "url_selector": "a.project-link",
            "requires_selenium": True,
            "anti_detection": True,
            "rate_limits": {"requests_per_minute": 4, "requests_per_hour": 40}
        },
        "free-lance_ru": {
            "base_url": "https://free-lance.ru",
            "search_pattern": "/search/?q={query}",
            "job_selector": ".project-item",
            "title_selector": ".project-title",
            "price_selector": ".project-price",
            "url_selector": "a.project-link",
            "requires_selenium": False,
            "anti_detection": False,
            "rate_limits": {"requests_per_minute": 7, "requests_per_hour": 70}
        },
        "telegram_channels": {
            "type": "telegram",
            "channels": [
                "@freelance_jobs_ru",
                "@copywriting_jobs",
                "@design_orders",
                "@programming_jobs_ru"
            ],
            "keywords": ["–∑–∞–∫–∞–∑", "–Ω—É–∂–µ–Ω", "—Ç—Ä–µ–±—É–µ—Ç—Å—è", "–∏—â—É –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è"],
            "anti_flood": True,
            "rate_limits": {"messages_per_hour": 20}
        }
    }

    def __init__(self,
                 platform_name: str,
                 config_path: Optional[str] = None,
                 credentials_path: str = "config/credentials/"):
        self.platform_name = platform_name
        self.credentials_path = Path(credentials_path)
        self.encryption_engine = EncryptionEngine()
        self.alert_manager = AlertManager()
        self.ai_hub = get_ai_model_hub()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if config_path:
            self.config = self._load_custom_config(config_path)
        elif platform_name in self.BUILT_IN_CONFIGS:
            self.config = self.BUILT_IN_CONFIGS[platform_name]
        else:
            raise ValueError(f"–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ '{platform_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –∏ –Ω–µ —É–∫–∞–∑–∞–Ω –∫–∞—Å—Ç–æ–º–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
        self.session = requests.Session()
        self._setup_session()

        # –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.credentials = self._load_credentials()
        self.is_authenticated = False

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —Ä–µ–π—Ç-–ª–∏–º–∏—Ç—ã
        self.request_timestamps = []
        self.hourly_request_count = 0
        self.last_captcha_time = None

    def _load_custom_config(self, config_path: str) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ YAML/JSON"""
        config_file = Path(config_path)
        if not config_file.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")

        if config_file.suffix == '.yaml' or config_file.suffix == '.yml':
            import yaml
            with open(config_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        else:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)

    def _load_credentials(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        cred_file = self.credentials_path / f"{self.platform_name}.enc"
        if cred_file.exists():
            try:
                encrypted = cred_file.read_bytes()
                decrypted = self.encryption_engine.decrypt(encrypted)
                return json.loads(decrypted.decode('utf-8'))
            except Exception as e:
                self._log(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}", level='ERROR')
        return {}

    def _setup_session(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ —Å –∏–º–∏—Ç–∞—Ü–∏–µ–π –±—Ä–∞—É–∑–µ—Ä–∞"""
        # –†–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è User-Agent
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
        ]

        self.session.headers.update({
            'User-Agent': random.choice(user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        })

        # –ü—Ä–æ–∫—Å–∏ (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã)
        if self.config.get('use_proxy'):
            proxy = self._get_random_proxy()
            if proxy:
                self.session.proxies = {'http': proxy, 'https': proxy}

    def _enforce_rate_limits(self):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–π—Ç-–ª–∏–º–∏—Ç–æ–≤ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–∞–Ω–∞"""
        now = datetime.now()

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
        self.request_timestamps = [
            ts for ts in self.request_timestamps
            if (now - ts).total_seconds() < 60
        ]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –≤ –º–∏–Ω—É—Ç—É
        per_minute_limit = self.config.get('rate_limits', {}).get('requests_per_minute', 10)
        if len(self.request_timestamps) >= per_minute_limit:
            sleep_time = 60 - (now - self.request_timestamps[0]).total_seconds()
            if sleep_time > 0:
                self._log(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç —Ä–µ–π—Ç-–ª–∏–º–∏—Ç ({per_minute_limit}/–º–∏–Ω). –°–æ–Ω {sleep_time:.1f} —Å–µ–∫...",
                          level='WARNING')
                time.sleep(sleep_time + 1)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –≤ —á–∞—Å
        per_hour_limit = self.config.get('rate_limits', {}).get('requests_per_hour', 100)
        if self.hourly_request_count >= per_hour_limit:
            sleep_time = 3600 - (now - self.request_timestamps[0]).total_seconds()
            if sleep_time > 0:
                self._log(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç —Ä–µ–π—Ç-–ª–∏–º–∏—Ç ({per_hour_limit}/—á–∞—Å). –°–æ–Ω {sleep_time / 60:.1f} –º–∏–Ω...",
                          level='CRITICAL')
                time.sleep(sleep_time + 60)
                self.hourly_request_count = 0

        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
        self.request_timestamps.append(now)
        self.hourly_request_count += 1

    def authenticate(self) -> bool:
        """
        –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è).
        –ü–æ–¥–¥–µ—Ä–∂–∫–∞: –ª–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å, –∫—É–∫–∏, —Ç–æ–∫–µ–Ω—ã, 2FA.
        """
        if self.is_authenticated:
            return True

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–µ—Å—Å–∏–∏
        if self._check_session():
            self.is_authenticated = True
            self._log("–°–µ—Å—Å–∏—è –∞–∫—Ç–∏–≤–Ω–∞, –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            return True

        # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ç–∏–ø—É –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        auth_method = self.config.get('auth_method', 'cookie')

        if auth_method == 'login_form':
            return self._login_via_form()
        elif auth_method == 'cookie':
            return self._login_via_cookie()
        elif auth_method == 'token':
            return self._login_via_token()
        elif auth_method == 'telegram':
            return self._login_via_telegram()

        self._log("–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —ç—Ç–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã")
        self.is_authenticated = True
        return True

    def _check_session(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–µ—Å—Å–∏–∏"""
        try:
            test_url = self.config.get('session_check_url', f"{self.config['base_url']}/")
            response = self.session.get(test_url, timeout=10)
            return response.status_code == 200 and 'login' not in response.url.lower()
        except:
            return False

    def _login_via_cookie(self) -> bool:
        """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫—É–∫–∏"""
        cookies = self.credentials.get('cookies', {})
        if not cookies:
            self._log("–ö—É–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏", level='WARNING')
            return False

        for name, value in cookies.items():
            self.session.cookies.set(name, value)

        if self._check_session():
            self._log("–£—Å–ø–µ—à–Ω–∞—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫—É–∫–∏")
            self.is_authenticated = True
            return True

        self._log("–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –∫—É–∫–∏", level='ERROR')
        return False

    def search_jobs(self,
                    query: str = "–∫–æ–ø–∏—Ä–∞–π—Ç–∏–Ω–≥ –¥–∏–∑–∞–π–Ω –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ",
                    filters: Optional[Dict[str, Any]] = None,
                    max_results: int = 30) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –∑–∞–∫–∞–∑–æ–≤ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ —Å –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã –∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π.

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
            filters: –§–∏–ª—å—Ç—Ä—ã (–±—é–¥–∂–µ—Ç, —Å—Ä–æ–∫–∏, –Ω–∞–≤—ã–∫–∏)
            max_results: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –∑–∞–∫–∞–∑–æ–≤ –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        """
        if not self.is_authenticated:
            if not self.authenticate():
                raise RuntimeError(f"–ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ {self.platform_name}")

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–π—Ç-–ª–∏–º–∏—Ç–æ–≤
        self._enforce_rate_limits()

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ URL –ø–æ–∏—Å–∫–∞
        search_url = self._build_search_url(query, filters)

        # –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
        if self.config.get('requires_selenium', False):
            html = self._scrape_with_selenium(search_url)
        else:
            html = self._scrape_with_requests(search_url)

        if not html:
            self._log("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã", level='ERROR')
            return []

        # –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–∫–∞–∑–æ–≤
        jobs = self._parse_jobs_from_html(html, max_results)

        # –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ò–ò
        filtered_jobs = self._ai_filter_jobs(jobs, filters)

        self._log(f"–ù–∞–π–¥–µ–Ω–æ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_jobs)} –∑–∞–∫–∞–∑–æ–≤ –Ω–∞ {self.platform_name}")
        return filtered_jobs

    def _build_search_url(self, query: str, filters: Optional[Dict[str, Any]]) -> str:
        """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ URL –ø–æ–∏—Å–∫–∞ —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
        base_url = self.config['base_url']
        search_pattern = self.config.get('search_pattern', '/search?q={query}')

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        keywords = query.split()[:3]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞
        search_query = '+'.join(keywords)

        url = f"{base_url}{search_pattern.format(query=search_query)}"

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        if filters:
            filter_params = []
            if filters.get('min_budget'):
                filter_params.append(f"budget_min={filters['min_budget']}")
            if filters.get('max_budget'):
                filter_params.append(f"budget_max={filters['max_budget']}")
            if filters.get('category'):
                filter_params.append(f"category={filters['category']}")

            if filter_params:
                url += "&" + "&".join(filter_params)

        return url

    def _scrape_with_requests(self, url: str) -> Optional[str]:
        """–°–∫—Ä–∞–ø–∏–Ω–≥ —á–µ—Ä–µ–∑ requests —Å –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã"""
        try:
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞
            time.sleep(random.uniform(1.5, 3.5))

            response = self.session.get(url, timeout=15)
            response.raise_for_status()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Cloudflare/–∑–∞—â–∏—Ç—É
            if 'cloudflare' in response.text.lower() or 'checking your browser' in response.text.lower():
                self._log("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∑–∞—â–∏—Ç–∞ Cloudflare, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ Selenium", level='WARNING')
                return self._scrape_with_selenium(url)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ø—á—É
            if self._detect_captcha(response.text):
                self._log("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞, —Ä–µ—à–µ–Ω–∏–µ...", level='WARNING')
                return self._solve_captcha_and_retry(url)

            return response.text

        except Exception as e:
            self._log(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ requests: {e}", level='ERROR')
            return None

    def _scrape_with_selenium(self, url: str) -> Optional[str]:
        """–°–∫—Ä–∞–ø–∏–Ω–≥ —á–µ—Ä–µ–∑ Selenium —Å –æ–±—Ö–æ–¥–æ–º –¥–µ—Ç–µ–∫—Ç–∞"""
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–±-–¥—Ä–∞–π–≤–µ—Ä–∞
            options = webdriver.ChromeOptions()
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')

            if self.config.get('headless', True):
                options.add_argument('--headless')

            driver = webdriver.Chrome(options=options)

            # –û–±—Ö–æ–¥ –¥–µ—Ç–µ–∫—Ç–∞ Selenium
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                "userAgent": self.session.headers['User-Agent']
            })

            # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
            driver.get(url)

            # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            job_selector = self.config.get('job_selector', '.job-item')
            try:
                WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, job_selector))
                )
            except TimeoutException:
                self._log("–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", level='WARNING')

            # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if self.config.get('infinite_scroll', False):
                self._scroll_to_load_more(driver, max_scrolls=3)

            # –ü–æ–ª—É—á–µ–Ω–∏–µ HTML
            html = driver.page_source
            driver.quit()

            return html

        except Exception as e:
            self._log(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ Selenium: {e}", level='ERROR')
            return None

    def _scroll_to_load_more(self, driver, max_scrolls: int = 3):
        """–ü—Ä–æ–∫—Ä—É—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        last_height = driver.execute_script("return document.body.scrollHeight")

        for _ in range(max_scrolls):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(2.0, 4.0))  # –†–∞–Ω–¥–æ–º–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞

            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

    def _parse_jobs_from_html(self, html: str, max_results: int = 30) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–∫–∞–∑–æ–≤ –∏–∑ HTML —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –ø—Ä–∞–≤–∏–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        soup = BeautifulSoup(html, 'html.parser')
        job_elements = soup.select(self.config['job_selector'])

        jobs = []
        for element in job_elements[:max_results]:
            try:
                job = self._extract_job_data(element)
                if job:
                    jobs.append(job)
            except Exception as e:
                self._log(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–∞: {e}", level='DEBUG')

        return jobs

    def _extract_job_data(self, element: Any) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–∞ –∏–∑ HTML-—ç–ª–µ–º–µ–Ω—Ç–∞"""
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_elem = element.select_one(self.config.get('title_selector'))
        title = title_elem.get_text(strip=True) if title_elem else None
        if not title:
            return None

        # –¶–µ–Ω–∞
        price = 0.0
        price_elem = element.select_one(self.config.get('price_selector'))
        if price_elem:
            price_text = price_elem.get_text(strip=True)
            price = self._extract_price(price_text)

        # URL
        url_elem = element.select_one(self.config.get('url_selector'))
        url = url_elem['href'] if url_elem else ''
        if url and not url.startswith('http'):
            url = self.config['base_url'] + url

        # ID –∑–∞–∫–∞–∑–∞ (—Ö–µ—à –æ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ + —Ü–µ–Ω—ã)
        job_id = hashlib.md5(f"{title}{price}".encode()).hexdigest()[:16]

        # –û–ø–∏—Å–∞–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        description = ''
        desc_selector = self.config.get('description_selector')
        if desc_selector:
            desc_elem = element.select_one(desc_selector)
            if desc_elem:
                description = desc_elem.get_text(strip=True)[:500]

        # –ù–∞–≤—ã–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        skills = []
        skills_selector = self.config.get('skills_selector')
        if skills_selector:
            skills_elems = element.select(skills_selector)
            skills = [s.get_text(strip=True) for s in skills_elems]

        return {
            'platform': self.platform_name,
            'job_id': job_id,
            'title': title,
            'description': description,
            'budget': {
                'amount': price,
                'currency': self.config.get('currency', 'RUB'),
                'type': 'fixed'
            },
            'skills': skills,
            'url': url,
            'posted_at': datetime.now().isoformat(),
            'raw_html': str(element)[:1000]  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
        }

    def _extract_price(self, text: str) -> float:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        # –ü–æ–∏—Å–∫ —á–∏—Å–µ–ª —Å –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
        match = re.search(r'[\d\s,.]+', text.replace(' ', '').replace(',', '.'))
        if match:
            try:
                return float(match.group(0).replace(' ', '').replace(',', '.'))
            except:
                pass
        return 0.0

    def _detect_captcha(self, html: str) -> bool:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–ø—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        captcha_indicators = [
            'captcha', 'hcaptcha', 'recaptcha', 'cloudflare-captcha',
            'verify you are human', 'robot', 'not a robot'
        ]
        html_lower = html.lower()
        return any(indicator in html_lower for indicator in captcha_indicators)

    def _solve_captcha_and_retry(self, url: str) -> Optional[str]:
        """–†–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏ —á–µ—Ä–µ–∑ 2Captcha/AntiCaptcha –∏ –ø–æ–≤—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞"""
        captcha_solver = self.config.get('captcha_solver')
        if not captcha_solver:
            self._log("–†–µ—à–∞—Ç–µ–ª—å –∫–∞–ø—á–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω", level='ERROR')
            return None

        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–µ—Ä–≤–∏—Å–æ–º —Ä–µ—à–µ–Ω–∏—è –∫–∞–ø—á–∏
        # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ ‚Äî —Å–∏–º—É–ª—è—Ü–∏—è
        self._log(f"–†–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏ —á–µ—Ä–µ–∑ {captcha_solver}...", level='INFO')
        time.sleep(10)  # –°–∏–º—É–ª—è—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ —Ä–µ—à–µ–Ω–∏—è

        # –ü–æ–≤—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞
        return self._scrape_with_requests(url)

    def _ai_filter_jobs(self, jobs: List[Dict[str, Any]], filters: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–∫–∞–∑–æ–≤ —á–µ—Ä–µ–∑ –ò–ò:
        - –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–∞–º–∞ –∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–∫–∞–∑–æ–≤
        - –û—Ü–µ–Ω–∫–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ –±—é–¥–∂–µ—Ç–∞
        - –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–ø–∏—Å–∞–Ω–∏—è –¢–ó
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        """
        if not jobs:
            return []

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
        try:
            model = self.ai_hub.get_model(task_type='sentiment_analysis', language='ru')
        except:
            # –ï—Å–ª–∏ –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –±–∞–∑–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            return self._basic_filter_jobs(jobs, filters)

        filtered_jobs = []

        for job in jobs:
            # –ê–Ω–∞–ª–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –∑–∞–∫–∞–∑–∞
            analysis = model(job['description'] or job['title'])

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
            is_quality = self._evaluate_job_quality(job, analysis, filters)

            if is_quality:
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ò–ò
                job['ai_analysis'] = {
                    'quality_score': analysis.get('score', 0.5),
                    'sentiment': analysis.get('label', 'neutral'),
                    'priority': self._calculate_priority(job, analysis),
                    'spam_probability': self._detect_spam(job)
                }
                filtered_jobs.append(job)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        filtered_jobs.sort(key=lambda x: x['ai_analysis']['priority'], reverse=True)

        return filtered_jobs

    def _basic_filter_jobs(self, jobs: List[Dict[str, Any]], filters: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ë–∞–∑–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±–µ–∑ –ò–ò"""
        min_budget = filters.get('min_budget', 500) if filters else 500

        return [
            job for job in jobs
            if job.get('budget', {}).get('amount', 0) >= min_budget
               and len(job.get('title', '')) > 10
               and not self._is_spam_basic(job)
        ]

    def _evaluate_job_quality(self, job: Dict[str, Any], analysis: Dict[str, Any],
                              filters: Optional[Dict[str, Any]]) -> bool:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–∫–∞–∑–∞"""
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –±—é–¥–∂–µ—Ç
        min_budget = filters.get('min_budget', 500) if filters else 500
        if job['budget']['amount'] < min_budget:
            return False

        # –ê–Ω–∞–ª–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
        description = job.get('description', '')
        if len(description) < 50:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            return False

        # –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∞–º–∞
        if self._detect_spam(job) > 0.7:  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞ > 70%
            return False

        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–∫–∞–∑—ã —á–∞—Å—Ç–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ)
        if analysis.get('label') == 'negative' and analysis.get('score', 0) > 0.8:
            return False

        return True

    def _detect_spam(self, job: Dict[str, Any]) -> float:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∞–º–∞/–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ (0.0 - 1.0)"""
        title = job['title'].lower()
        description = job.get('description', '').lower()

        spam_keywords = [
            '—Å—Ä–æ—á–Ω', '–æ—á–µ–Ω—å —Å—Ä–æ—á–Ω', '–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ', '–±–µ–∑ –æ–ø–ª–∞—Ç—ã', '—Ç–µ—Å—Ç–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ',
            '–æ–ø–ª–∞—Ç–∞ –ø–æ—Å–ª–µ', '–ø—Ä–µ–¥–æ–ø–ª–∞—Ç–∞', '–≥–∞—Ä–∞–Ω—Ç', '100%', '–º–∏–ª–ª–∏–æ–Ω', '–ª–µ–≥–∫–æ',
            '–±–µ–∑ –æ–ø—ã—Ç–∞', '–¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤', '–∑–∞ 5 –º–∏–Ω—É—Ç', '—É–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞',
            '–∑–∞—Ä–∞–±–æ—Ç–æ–∫', '–¥–µ–Ω—å–≥–∏', '–æ–ø–ª–∞—Ç–∞ –Ω–∞ –∫–∞—Ä—Ç—É'
        ]

        spam_score = sum(1 for kw in spam_keywords if kw in title or kw in description) / len(spam_keywords)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
        if job['budget']['amount'] < 300:  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –±—é–¥–∂–µ—Ç
            spam_score += 0.3
        if len(job['title']) < 15:  # –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
            spam_score += 0.2

        return min(1.0, spam_score)

    def _is_spam_basic(self, job: Dict[str, Any]) -> bool:
        """–ë–∞–∑–æ–≤–æ–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∞–º–∞ –±–µ–∑ –ò–ò"""
        title = job['title'].lower()
        spam_triggers = ['—Å—Ä–æ—á–Ω', '—Ç–µ—Å—Ç–æ–≤–æ–µ', '–±–µ–∑ –æ–ø–ª–∞—Ç—ã', '–≥–∞—Ä–∞–Ω—Ç', '100%']
        return any(trigger in title for trigger in spam_triggers) or job['budget']['amount'] < 300

    def _calculate_priority(self, job: Dict[str, Any], analysis: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –∑–∞–∫–∞–∑–∞ (0.0 - 1.0)"""
        priority = 0.0

        # –ë—é–¥–∂–µ—Ç (—á–µ–º –≤—ã—à–µ, —Ç–µ–º –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        budget = job['budget']['amount']
        priority += min(budget / 10000, 0.4)  # –ú–∞–∫—Å–∏–º—É–º 0.4 –∑–∞ –±—é–¥–∂–µ—Ç

        # –ö–∞—á–µ—Å—Ç–≤–æ –æ–ø–∏—Å–∞–Ω–∏—è
        desc_quality = len(job.get('description', '')) / 500
        priority += min(desc_quality * 0.3, 0.3)

        # –ê–Ω–∞–ª–∏–∑ –ò–ò
        ai_score = analysis.get('score', 0.5)
        priority += ai_score * 0.3

        return min(1.0, priority)

    def submit_proposal(self, job_id: str, proposal_text: str, amount: Optional[float] = None) -> Dict[str, Any]:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ –∑–∞–∫–∞–∑ (–µ—Å–ª–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç).
        –î–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ "—Å–µ—Ä—ã—Ö" –ø–ª–æ—â–∞–¥–æ–∫ ‚Äî —Ç–æ–ª—å–∫–æ —Ä—É—á–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ.
        """
        # –î–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–æ–≤—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º –æ—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–∫–ª–∏–∫–æ–≤ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞
        # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ ‚Äî —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self._notify_user_about_job(job_id, proposal_text, amount)

        return {
            'success': True,
            'message': '–ó–∞–∫–∞–∑ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ—Ç–∫–ª–∏–∫ –≤—Ä—É—á–Ω—É—é.',
            'notification_sent': True
        }

    def _notify_user_about_job(self, job_id: str, proposal_text: str, amount: Optional[float]):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ –Ω–∞–π–¥–µ–Ω–Ω–æ–º –∑–∞–∫–∞–∑–µ"""
        notification = {
            'platform': self.platform_name,
            'job_id': job_id,
            'message': f'–ù–∞–π–¥–µ–Ω –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π –∑–∞–∫–∞–∑ –Ω–∞ {self.platform_name}! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ—Ç–∫–ª–∏–∫ –≤—Ä—É—á–Ω—É—é.',
            'proposal_template': proposal_text,
            'suggested_amount': amount,
            'timestamp': datetime.now().isoformat()
        }

        # –û—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ Telegram
        try:
            from services.notification.telegram_service import TelegramService
            telegram = TelegramService()
            telegram.send_message(
                f"üîî –ù–û–í–´–ô –ó–ê–ö–ê–ó –Ω–∞ {self.platform_name}\n\n"
                f"ID: {job_id}\n"
                f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–∫–ª–∏–∫–∞:\n{proposal_text[:200]}...\n\n"
                f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Ü–µ–Ω–∞: {amount} ‚ÇΩ\n\n"
                f"–û—Ç–∫—Ä–æ–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–∫–ª–∏–∫–∞!"
            )
        except Exception as e:
            self._log(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}", level='WARNING')

    def _log(self, message: str, level: str = 'INFO'):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = f"[{timestamp}] [UniversalScraper:{self.platform_name}] [{level}] {message}"

        # –ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
        log_dir = Path("logs/platforms")
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / f"{self.platform_name}.log"

        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry + '\n')

        # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
        if level in ['ERROR', 'CRITICAL']:
            print(f"\033[91m{log_entry}\033[0m")
        elif level == 'WARNING':
            print(f"\033[93m{log_entry}\033[0m")

    @classmethod
    def get_all_available_platforms(cls) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        platforms = {
            'youla_freelance': 'Youla –£—Å–ª—É–≥–∏ (–†–æ—Å—Å–∏—è)',
            'avito_uslugi': '–ê–≤–∏—Ç–æ –£—Å–ª—É–≥–∏ (–†–æ—Å—Å–∏—è)',
            'irr_freelance': 'IRR –£—Å–ª—É–≥–∏ (–°–ù–ì)',
            'workzilla': 'Workzilla (–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è)',
            'weblancer': 'Weblancer (–°–ù–ì)',
            'experts': 'Experts.ru (–†–æ—Å—Å–∏—è)',
            'free-lance_ru': 'Free-lance.ru (–†–æ—Å—Å–∏—è)',
            'telegram_channels': 'Telegram-–∫–∞–Ω–∞–ª—ã —Å –∑–∞–∫–∞–∑–∞–º–∏'
        }
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–æ–≤
        custom_dir = Path("config/platforms/custom")
        if custom_dir.exists():
            for cfg in custom_dir.glob("*.yaml"):
                platforms[cfg.stem] = f"–ö–∞—Å—Ç–æ–º–Ω–∞—è: {cfg.stem}"

        return platforms


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä –∞–¥–∞–ø—Ç–µ—Ä–æ–≤
_scraper_adapters_registry = {}


def register_scraper_adapter(platform_name: str, adapter_class):
    """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∞–¥–∞–ø—Ç–µ—Ä–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞"""
    _scraper_adapters_registry[platform_name] = adapter_class


def get_scraper_adapter(platform_name: str, **kwargs) -> UniversalScraperAdapter:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
    if platform_name in _scraper_adapters_registry:
        return _scraper_adapters_registry[platform_name](platform_name, **kwargs)
    return UniversalScraperAdapter(platform_name, **kwargs)