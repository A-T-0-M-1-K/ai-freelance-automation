# AI_FREELANCE_AUTOMATION/scripts/maintenance/cleanup_old_data.py
"""
–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ—á–∏—Å—Ç–∫–∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
–£–¥–∞–ª—è–µ—Ç –∏–ª–∏ –∞—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –ª–æ–≥-—Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å—Ä–æ–∫–∞.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å —Å–∏—Å—Ç–µ–º–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏) –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ.
"""

import os
import shutil
import logging
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∫ –º–æ–¥—É–ª—å,
# –Ω–æ –¥–ª—è standalone-—Å–∫—Ä–∏–ø—Ç–∞ ‚Äî –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏ —á–µ—Ä–µ–∑ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞.
# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞.

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger("Maintenance.Cleanup")

# –ü—É—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–º–æ–≥—É—Ç –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥)
DEFAULT_CONFIG_PATH = "config/automation.json"
CLEANUP_RULES_SCHEMA = {
    "logs": {"age_days": 30, "enabled": True},
    "cache": {"age_days": 7, "enabled": True},
    "temp_ai": {"age_days": 1, "enabled": True},
    "backup_automatic": {"age_days": 90, "enabled": False},  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ —É–¥–∞–ª—è–µ–º –±—ç–∫–∞–ø—ã
    "conversations": {"age_days": 180, "enabled": True},
}


def load_cleanup_config(config_path: str = DEFAULT_CONFIG_PATH) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –æ—á–∏—Å—Ç–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    try:
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                config = json.load(f)
            return config.get("cleanup_rules", CLEANUP_RULES_SCHEMA)
        else:
            logger.warning(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è {config_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return CLEANUP_RULES_SCHEMA
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏: {e}")
        return CLEANUP_RULES_SCHEMA


def is_older_than(path: Path, days: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—Ç–∞—Ä—à–µ –ª–∏ —Ñ–∞–π–ª/–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π."""
    try:
        stat = path.stat()
        file_time = datetime.fromtimestamp(max(stat.st_mtime, stat.st_ctime))
        return datetime.now() - file_time > timedelta(days=days)
    except OSError as e:
        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º—è –¥–ª—è {path}: {e}")
        return False


def safe_remove(path: Path) -> bool:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é."""
    try:
        if path.is_file():
            path.unlink()
            logger.debug(f"–£–¥–∞–ª—ë–Ω —Ñ–∞–π–ª: {path}")
        elif path.is_dir():
            shutil.rmtree(path)
            logger.debug(f"–£–¥–∞–ª–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {path}")
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {path}: {e}")
        return False


def cleanup_directory(root: Path, max_age_days: int, dry_run: bool = False) -> int:
    """–û—á–∏—â–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –æ—Ç —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ max_age_days."""
    deleted_count = 0
    if not root.exists():
        logger.debug(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {root}")
        return 0

    for item in root.rglob("*"):
        if item.is_file() and is_older_than(item, max_age_days):
            if not dry_run:
                if safe_remove(item):
                    deleted_count += 1
            else:
                logger.info(f"[DRY RUN] –ë—É–¥–µ—Ç —É–¥–∞–ª—ë–Ω: {item}")
                deleted_count += 1

    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ dry_run)
    if not dry_run:
        for dir_item in sorted(root.rglob("*"), key=lambda x: len(str(x)), reverse=True):
            if dir_item.is_dir() and not any(dir_item.iterdir()):
                try:
                    dir_item.rmdir()
                    logger.debug(f"–£–¥–∞–ª–µ–Ω–∞ –ø—É—Å—Ç–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {dir_item}")
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø—É—Å—Ç—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é {dir_item}: {e}")

    return deleted_count


def run_cleanup(dry_run: bool = False) -> Dict[str, int]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é –æ—á–∏—Å—Ç–∫—É —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–∞–≤–∏–ª–∞–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —É–¥–∞–ª—ë–Ω–Ω—ã–º –æ–±—ä–µ–∫—Ç–∞–º.
    """
    config = load_cleanup_config()
    stats = {}

    paths_map = {
        "logs": Path("logs"),
        "cache": Path("data/cache"),
        "temp_ai": Path("ai/temp"),
        "backup_automatic": Path("backup/automatic"),
        "conversations": Path("data/conversations"),
    }

    for category, rules in config.items():
        if not rules.get("enabled", False):
            continue

        age_days = rules.get("age_days", 30)
        target_path = paths_map.get(category)

        if not target_path or not target_path.exists():
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è {category}: –ø—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            continue

        logger.info(f"–û—á–∏—Å—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' (—Å—Ç–∞—Ä—à–µ {age_days} –¥–Ω–µ–π)...")
        deleted = cleanup_directory(target_path, age_days, dry_run=dry_run)
        stats[category] = deleted
        logger.info(f"–£–¥–∞–ª–µ–Ω–æ {deleted} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'")

    return stats


def main(dry_run: bool = False):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è CLI –∏–ª–∏ cron."""
    log_file = Path("logs/app/maintenance.log")
    log_file.parent.mkdir(parents=True, exist_ok=True)

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8"),
            logging.StreamHandler()
        ]
    )

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –æ—á–∏—Å—Ç–∫–∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    stats = run_cleanup(dry_run=dry_run)

    total_deleted = sum(stats.values())
    if dry_run:
        logger.info(f"‚úÖ DRY RUN –∑–∞–≤–µ—Ä—à—ë–Ω. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_deleted} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")
    else:
        logger.info(f"‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£–¥–∞–ª–µ–Ω–æ {total_deleted} —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á—ë—Ç –≤ data/stats/
    report_path = Path("data/stats/cleanup_report.json")
    report_path.parent.mkdir(parents=True, exist_ok=True)
    report = {
        "timestamp": datetime.now().isoformat(),
        "dry_run": dry_run,
        "stats": stats,
        "total_deleted": total_deleted
    }
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    logger.info(f"üìÑ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º—ã")
    parser.add_argument("--dry-run", action="store_true", help="–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ")
    args = parser.parse_args()
    main(dry_run=args.dry_run)