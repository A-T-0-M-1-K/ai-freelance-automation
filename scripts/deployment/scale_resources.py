# AI_FREELANCE_AUTOMATION/scripts/deployment/scale_resources.py
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ –Ω–∞–≥—Ä—É–∑–∫–∏.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å monitoring, config –∏ performance –ø–æ–¥—Å–∏—Å—Ç–µ–º–∞–º–∏.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ.
"""

import asyncio
import logging
import json
from typing import Dict, Any, Optional
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ —è–¥—Ä–∞ (—á–µ—Ä–µ–∑ service locator –∏–ª–∏ –Ω–∞–ø—Ä—è–º—É—é ‚Äî –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö –¥–æ–ø—É—Å—Ç–∏–º–æ)
from core.config.unified_config_manager import UnifiedConfigManager
from core.monitoring.intelligent_monitoring_system import IntelligentMonitoringSystem
from core.performance.intelligent_cache_system import IntelligentCacheSystem
from core.security.audit_logger import AuditLogger

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from scripts.deployment.deployment_utils import DeploymentUtils


class ResourceScaler:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–∏—Å—Ç–µ–º—ã.
    –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ standalone-—Å–∫—Ä–∏–ø—Ç –∏–ª–∏ –∫–∞–∫ —á–∞—Å—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∑–∞–¥–∞—á.
    """

    def __init__(self, config_path: Optional[str] = None):
        self.logger = logging.getLogger("ResourceScaler")
        self.config_manager = UnifiedConfigManager(config_path)
        self.monitoring = IntelligentMonitoringSystem(self.config_manager)
        self.cache_system = IntelligentCacheSystem(self.config_manager)
        self.audit_logger = AuditLogger()
        self.utils = DeploymentUtils()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        self.scaling_config = self.config_manager.get_section("scaling") or {}
        self.enabled = self.scaling_config.get("enabled", True)
        self.mode = self.scaling_config.get("mode", "auto")  # auto, manual, disabled
        self.thresholds = self.scaling_config.get("thresholds", {
            "cpu_high": 80,
            "memory_high": 85,
            "disk_io_high": 75,
            "active_jobs_high": 40,
            "concurrent_clients_high": 90
        })

        self.logger.info("Intialized ResourceScaler with mode: %s", self.mode)

    async def _get_current_load_metrics(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏ –∏–∑ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        metrics = await self.monitoring.collect_metrics([
            "system.cpu_usage",
            "system.memory_usage",
            "system.disk_io",
            "business.active_jobs",
            "business.concurrent_clients"
        ])
        return {
            "cpu": metrics.get("system.cpu_usage", 0.0),
            "memory": metrics.get("system.memory_usage", 0.0),
            "disk_io": metrics.get("system.disk_io", 0.0),
            "active_jobs": metrics.get("business.active_jobs", 0.0),
            "concurrent_clients": metrics.get("business.concurrent_clients", 0.0)
        }

    async def _should_scale_up(self, metrics: Dict[str, float]) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã."""
        if metrics["cpu"] > self.thresholds["cpu_high"]:
            self.logger.warning("CPU usage %.2f%% exceeds threshold", metrics["cpu"])
            return True
        if metrics["memory"] > self.thresholds["memory_high"]:
            self.logger.warning("Memory usage %.2f%% exceeds threshold", metrics["memory"])
            return True
        if metrics["active_jobs"] > self.thresholds["active_jobs_high"]:
            self.logger.info("Active jobs (%d) exceed threshold", int(metrics["active_jobs"]))
            return True
        return False

    async def _should_scale_down(self, metrics: Dict[str, float]) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ —É–º–µ–Ω—å—à–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏)."""
        low_threshold = {k: v * 0.4 for k, v in self.thresholds.items()}
        return all(
            metrics.get(key, 0) < low_threshold.get(f"{key}_high", 30)
            for key in ["cpu", "memory", "active_jobs"]
        )

    async def _scale_vertical(self, direction: str) -> bool:
        """–í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (—É–≤–µ–ª–∏—á–µ–Ω–∏–µ CPU/RAM –Ω–∞ —Ç–µ–∫—É—â–µ–º —Ö–æ—Å—Ç–µ)."""
        try:
            self.logger.info("üîÑ Performing vertical scaling: %s", direction)
            success = await self.utils.adjust_local_resources(direction)
            if success:
                self.audit_logger.log("scaling.vertical", {
                    "action": "vertical_scale",
                    "direction": direction,
                    "status": "success"
                })
                self.logger.info("‚úÖ Vertical scaling %s completed", direction)
            else:
                self.logger.error("‚ùå Vertical scaling %s failed", direction)
            return success
        except Exception as e:
            self.logger.exception("üí• Error during vertical scaling: %s", e)
            self.audit_logger.log("scaling.vertical.error", {"error": str(e)})
            return False

    async def _scale_horizontal(self, direction: str) -> bool:
        """–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (–∑–∞–ø—É—Å–∫/–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –Ω–æ–¥)."""
        try:
            self.logger.info("üîÑ Performing horizontal scaling: %s", direction)
            success = await self.utils.manage_worker_nodes(direction)
            if success:
                self.audit_logger.log("scaling.horizontal", {
                    "action": "horizontal_scale",
                    "direction": direction,
                    "status": "success"
                })
                self.logger.info("‚úÖ Horizontal scaling %s completed", direction)
            else:
                self.logger.error("‚ùå Horizontal scaling %s failed", direction)
            return success
        except Exception as e:
            self.logger.exception("üí• Error during horizontal scaling: %s", e)
            self.audit_logger.log("scaling.horizontal.error", {"error": str(e)})
            return False

    async def _optimize_cache_before_scaling(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∫—ç—à –ø–µ—Ä–µ–¥ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏."""
        self.logger.info("üßπ Optimizing cache before scaling...")
        await self.cache_system.evict_low_priority()
        await self.cache_system.preload_predicted()

    async def scale_resources(self) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—á–µ—Ç –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏.
        """
        if not self.enabled or self.mode == "disabled":
            self.logger.info("‚ö†Ô∏è Resource scaling is disabled")
            return {"status": "disabled"}

        self.logger.info("üîç Analyzing system load for scaling decision...")
        metrics = await self._get_current_load_metrics()
        self.logger.debug("Current metrics: %s", json.dumps(metrics, indent=2))

        report = {
            "metrics": metrics,
            "actions": [],
            "status": "no_action"
        }

        if await self._should_scale_up(metrics):
            await self._optimize_cache_before_scaling()
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ)
            if await self._scale_horizontal("up"):
                report["actions"].append("horizontal_up")
                report["status"] = "scaled_up"
            elif await self._scale_vertical("up"):
                report["actions"].append("vertical_up")
                report["status"] = "scaled_up"
            else:
                report["status"] = "scaling_failed"
                self.logger.critical("üî• All scaling attempts failed!")

        elif await self._should_scale_down(metrics) and self.mode == "auto":
            if await self._scale_horizontal("down"):
                report["actions"].append("horizontal_down")
                report["status"] = "scaled_down"
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

        self.logger.info("üìä Scaling cycle completed. Status: %s", report["status"])
        return report

    async def run_once(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è."""
        return await self.scale_resources()


# === –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è CLI ===
if __name__ == "__main__":
    import argparse
    import sys

    parser = argparse.ArgumentParser(description="Scale system resources based on load")
    parser.add_argument("--config", type=str, help="Path to config file", default=None)
    parser.add_argument("--log-level", type=str, default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"])
    args = parser.parse_args()

    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        handlers=[
            logging.FileHandler("logs/deployment/scale_resources.log"),
            logging.StreamHandler(sys.stdout)
        ]
    )

    scaler = ResourceScaler(config_path=args.config)
    result = asyncio.run(scaler.run_once())

    print(json.dumps(result, indent=2, ensure_ascii=False))
    sys.exit(0 if result["status"] in ("scaled_up", "scaled_down", "no_action", "disabled") else 1)