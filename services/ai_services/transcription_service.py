# AI_FREELANCE_AUTOMATION/services/ai_services/transcription_service.py

"""
Transcription Service ‚Äî –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 50+ —è–∑—ã–∫–æ–≤.
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç 98%+ —Ç–æ—á–Ω–æ—Å—Ç—å, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞, –æ–±—Ä–∞–±–æ—Ç–∫—É —à—É–º–∞,
–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å workflow —Å–∏—Å—Ç–µ–º—ã —Ñ—Ä–∏–ª–∞–Ω—Å–∞.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏:
- OpenAI Whisper (local/cloud)
- Google Cloud Speech-to-Text
- Deepgram
- Custom fine-tuned models

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ü–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω –æ—Ç –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ —á–µ—Ä–µ–∑ DI
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç unified config –∏ logging
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç retry + fallback –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
- –õ–æ–≥–∏—Ä—É–µ—Ç –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ audit –∏ performance
"""

import asyncio
import logging
import os
import tempfile
import time
from pathlib import Path
from typing import Optional, Dict, Any, Union, List
from dataclasses import dataclass

from core.config.unified_config_manager import UnifiedConfigManager
from core.security.audit_logger import AuditLogger
from core.monitoring.intelligent_monitoring_system import MetricsCollector
from core.ai_management.intelligent_model_manager import IntelligentModelManager
from core.dependency.service_locator import ServiceLocator

# –¢–∏–ø—ã –æ—à–∏–±–æ–∫
class TranscriptionError(Exception):
    """–ë–∞–∑–æ–≤–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏."""
    pass

class ModelLoadError(TranscriptionError):
    pass

class AudioProcessingError(TranscriptionError):
    pass

class ProviderError(TranscriptionError):
    pass

@dataclass
class TranscriptionResult:
    text: str
    language: str
    confidence: float
    processing_time_sec: float
    model_used: str
    word_timestamps: Optional[List[Dict[str, Union[float, str]]]] = None
    metadata: Optional[Dict[str, Any]] = None


class TranscriptionService:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å —Å–µ—Ä–≤–∏—Å–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.
    –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ singleton —á–µ—Ä–µ–∑ ServiceLocator.
    """

    def __init__(self, config: Optional[UnifiedConfigManager] = None):
        self.logger = logging.getLogger("TranscriptionService")
        self.config = config or ServiceLocator.get("config")
        self.audit_logger = AuditLogger()
        self.metrics = MetricsCollector()
        self.model_manager = ServiceLocator.get("ai_manager")  # type: IntelligentModelManager

        self._initialized = False
        self._supported_providers = ["whisper", "google_stt", "deepgram"]
        self._default_provider = self.config.get("ai.transcription.provider", "whisper")

        self.logger.info("Intialized TranscriptionService with provider: %s", self._default_provider)

    async def initialize(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –∏ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        if self._initialized:
            return
        try:
            await self.model_manager.load_model_family("transcription")
            self._initialized = True
            self.logger.info("‚úÖ Transcription models loaded successfully.")
        except Exception as e:
            self.logger.error("‚ùå Failed to initialize transcription models: %s", e)
            raise ModelLoadError(f"Model init failed: {e}")

    async def transcribe(
        self,
        audio_path: Union[str, Path],
        language: Optional[str] = None,
        task_id: Optional[str] = None,
        client_id: Optional[str] = None,
        enable_timestamps: bool = False,
        max_retries: int = 3
    ) -> TranscriptionResult:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.

        Args:
            audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
            language: —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
            task_id: ID –∑–∞–¥–∞—á–∏ –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
            client_id: ID –∫–ª–∏–µ–Ω—Ç–∞ (–¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∞—É–¥–∏—Ç–∞)
            enable_timestamps: –≤–∫–ª—é—á–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Å–ª–æ–≤
            max_retries: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ

        Returns:
            TranscriptionResult ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç

        Raises:
            TranscriptionError ‚Äî –µ—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å
        """
        start_time = time.time()
        audio_path = Path(audio_path)

        if not audio_path.exists():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")

        self.audit_logger.log(
            action="transcription_start",
            actor="ai_service",
            resource=str(audio_path),
            details={"task_id": task_id, "client_id": client_id}
        )

        # –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ + fallback
        providers_to_try = [self._default_provider] + [
            p for p in self._supported_providers if p != self._default_provider
        ]

        last_error = None
        for attempt, provider in enumerate(providers_to_try[:max_retries], 1):
            try:
                self.logger.info("üéôÔ∏è Attempt %d/%d: transcribing with %s", attempt, max_retries, provider)
                result = await self._transcribe_with_provider(
                    provider=provider,
                    audio_path=audio_path,
                    language=language,
                    enable_timestamps=enable_timestamps
                )
                processing_time = time.time() - start_time

                final_result = TranscriptionResult(
                    text=result["text"],
                    language=result.get("language", "auto"),
                    confidence=result.get("confidence", 0.95),
                    processing_time_sec=processing_time,
                    model_used=provider,
                    word_timestamps=result.get("word_timestamps"),
                    metadata={
                        "provider": provider,
                        "task_id": task_id,
                        "client_id": client_id,
                        "file_size_mb": os.path.getsize(audio_path) / (1024 * 1024)
                    }
                )

                # –ú–µ—Ç—Ä–∏–∫–∏
                self.metrics.record("transcription.success", 1)
                self.metrics.record("transcription.duration_sec", processing_time)
                self.metrics.record("transcription.confidence", final_result.confidence)

                self.audit_logger.log(
                    action="transcription_success",
                    actor="ai_service",
                    resource=str(audio_path),
                    details={"result": final_result.metadata}
                )

                return final_result

            except Exception as e:
                last_error = e
                self.logger.warning("‚ö†Ô∏è Provider %s failed: %s", provider, e)
                self.metrics.record("transcription.failure", 1)
                await asyncio.sleep(0.5 * attempt)  # —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞

        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        error_msg = f"All transcription providers failed after {max_retries} attempts. Last error: {last_error}"
        self.logger.error("üí• %s", error_msg)
        self.audit_logger.log(
            action="transcription_failure",
            actor="ai_service",
            resource=str(audio_path),
            details={"error": str(last_error), "task_id": task_id}
        )
        raise TranscriptionError(error_msg)

    async def _transcribe_with_provider(
        self,
        provider: str,
        audio_path: Path,
        language: Optional[str] = None,
        enable_timestamps: bool = False
    ) -> Dict[str, Any]:
        """–í—ã–∑–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
        if provider == "whisper":
            return await self._run_whisper(audio_path, language, enable_timestamps)
        elif provider == "google_stt":
            return await self._run_google_stt(audio_path, language)
        elif provider == "deepgram":
            return await self._run_deepgram(audio_path, language)
        else:
            raise ValueError(f"Unsupported provider: {provider}")

    async def _run_whisper(
        self,
        audio_path: Path,
        language: Optional[str],
        enable_timestamps: bool
    ) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –∏–ª–∏ –æ–±–ª–∞—á–Ω–æ–π Whisper-–º–æ–¥–µ–ª–∏."""
        try:
            model = await self.model_manager.get_model("whisper", language=language)
            result = await model.transcribe(
                str(audio_path),
                language=language,
                word_timestamps=enable_timestamps,
                fp16=False  # –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ –Ω–∞ CPU
            )
            return {
                "text": result["text"].strip(),
                "language": result.get("language", "unknown"),
                "confidence": self._estimate_confidence_from_segments(result.get("segments", [])),
                "word_timestamps": result.get("segments") if enable_timestamps else None
            }
        except Exception as e:
            raise ProviderError(f"Whisper failed: {e}")

    async def _run_google_stt(self, audio_path: Path, language: Optional[str]) -> Dict[str, Any]:
        """Google Cloud Speech-to-Text (–∑–∞–≥–ª—É—à–∫–∞ ‚Äî –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)."""
        raise NotImplementedError("Google STT integration not implemented yet")

    async def _run_deepgram(self, audio_path: Path, language: Optional[str]) -> Dict[str, Any]:
        """Deepgram API (–∑–∞–≥–ª—É—à–∫–∞)."""
        raise NotImplementedError("Deepgram integration not implemented yet")

    def _estimate_confidence_from_segments(self, segments: List[Dict]) -> float:
        """–û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ Whisper."""
        if not segments:
            return 0.0
        confidences = [seg.get("avg_logprob", -1.0) for seg in segments]
        # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: logprob ‚Üí [0,1]
        normalized = [(c + 5.0) / 5.0 for c in confidences]  # —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏
        return max(0.0, min(1.0, sum(normalized) / len(normalized)))

    async def cleanup_temp_files(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ workflow_orchestrator)."""
        # –í —ç—Ç–æ–º —Å–µ—Ä–≤–∏—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–µ —Å–æ–∑–¥–∞—é—Ç—Å—è ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ Path
        pass


# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ ServiceLocator (–ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ)
def register_transcription_service():
    """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å–µ—Ä–≤–∏—Å –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π."""
    from core.dependency.service_locator import ServiceLocator
    service = TranscriptionService()
    ServiceLocator.register("transcription_service", service)


# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
register_transcription_service()