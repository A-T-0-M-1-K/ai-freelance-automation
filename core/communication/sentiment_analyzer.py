# AI_FREELANCE_AUTOMATION/core/communication/sentiment_analyzer.py

"""
Sentiment Analyzer ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —Ç–æ–Ω–∞ –æ–±—â–µ–Ω–∏—è, –≤—ã—è–≤–ª–µ–Ω–∏—è –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 50+ —è–∑—ã–∫–æ–≤, —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏, —É—Å—Ç–æ–π—á–∏–≤ –∫ —Å–±–æ—è–º.
"""

import logging
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from core.config.unified_config_manager import UnifiedConfigManager
from core.ai_management.intelligent_model_manager import IntelligentModelManager
from core.performance.intelligent_cache_system import IntelligentCacheSystem
from core.security.audit_logger import AuditLogger

logger = logging.getLogger("SentimentAnalyzer")


class SentimentLabel(Enum):
    VERY_NEGATIVE = -2
    NEGATIVE = -1
    NEUTRAL = 0
    POSITIVE = 1
    VERY_POSITIVE = 2


@dataclass
class SentimentResult:
    label: SentimentLabel
    confidence: float  # 0.0 ‚Äì 1.0
    language: str
    raw_score: Optional[float] = None  # –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∫–æ—Ä –º–æ–¥–µ–ª–∏
    suggestions: Optional[Dict[str, Any]] = None  # —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è communicator'–∞


class SentimentAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤.

    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Ñ—Ä–∞–∑)
    - Fallback –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å–±–æ–µ
    - –ê—É–¥–∏—Ç –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ batch-–æ–±—Ä–∞–±–æ—Ç–∫–∏
    """

    def __init__(
            self,
            config: UnifiedConfigManager,
            ai_manager: IntelligentModelManager,
            cache: Optional[IntelligentCacheSystem] = None,
            audit_logger: Optional[AuditLogger] = None
    ):
        self.config = config
        self.ai_manager = ai_manager
        self.cache = cache or IntelligentCacheSystem(config)
        self.audit_logger = audit_logger or AuditLogger(config)
        self._initialized = False
        self._primary_model = None
        self._fallback_model = None
        self._load_models()

    def _load_models(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∏ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏."""
        try:
            sentiment_config = self.config.get("ai.sentiment", default={})
            primary_model_name = sentiment_config.get("primary_model",
                                                      "cardiffnlp/twitter-roberta-base-sentiment-latest")
            fallback_model_name = sentiment_config.get("fallback_model",
                                                       "nlptown/bert-base-multilingual-uncased-sentiment")

            logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {primary_model_name}")
            self._primary_model = self.ai_manager.load_model(
                model_name=primary_model_name,
                task="sentiment-analysis",
                auto_optimize=True
            )

            logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {fallback_model_name}")
            self._fallback_model = self.ai_manager.load_model(
                model_name=fallback_model_name,
                task="sentiment-analysis",
                auto_optimize=True
            )

            self._initialized = True
            logger.info("‚úÖ SentimentAnalyzer —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {e}", exc_info=True)
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å SentimentAnalyzer") from e

    def _normalize_label(self, model_label: str, model_name: str) -> SentimentLabel:
        """–ü—Ä–∏–≤–æ–¥–∏—Ç –º–µ—Ç–∫–∏ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É."""
        label_map = {
            # –î–ª—è cardiffnlp
            "LABEL_0": SentimentLabel.NEGATIVE,
            "LABEL_1": SentimentLabel.NEUTRAL,
            "LABEL_2": SentimentLabel.POSITIVE,
            # –î–ª—è nlptown (–æ—Ü–µ–Ω–∫–∏ 1‚Äì5)
            "1 star": SentimentLabel.VERY_NEGATIVE,
            "2 stars": SentimentLabel.NEGATIVE,
            "3 stars": SentimentLabel.NEUTRAL,
            "4 stars": SentimentLabel.POSITIVE,
            "5 stars": SentimentLabel.VERY_POSITIVE,
        }

        # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if model_label in label_map:
            return label_map[model_label]

        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ (–¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫)
        try:
            score = int(''.join(filter(str.isdigit, model_label)))
            if score <= 2:
                return SentimentLabel.NEGATIVE
            elif score == 3:
                return SentimentLabel.NEUTRAL
            else:
                return SentimentLabel.POSITIVE
        except ValueError:
            pass

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ
        logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–µ—Ç–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ '{model_label}' –æ—Ç –º–æ–¥–µ–ª–∏ '{model_name}', –≤–æ–∑–≤—Ä–∞—â–∞–µ–º NEUTRAL")
        return SentimentLabel.NEUTRAL

    def _analyze_with_model(self, text: str, model, model_name: str) -> Optional[SentimentResult]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª—å—é."""
        try:
            result = model(text)
            if not result or len(result) == 0:
                return None

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏
            prediction = result[0] if isinstance(result, list) else result
            label = prediction.get("label", "NEUTRAL")
            confidence = float(prediction.get("score", 0.0))

            normalized_label = self._normalize_label(label, model_name)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ AI –∏–ª–∏ fallback)
            language = self._detect_language(text)

            return SentimentResult(
                label=normalized_label,
                confidence=confidence,
                language=language,
                raw_score=prediction.get("score"),
                suggestions=self._generate_suggestions(normalized_label, confidence)
            )
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å '{model_name}' –Ω–µ —Å–º–æ–≥–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç: {e}")
            return None

    def _detect_language(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ (—É–ø—Ä–æ—â—ë–Ω–Ω–æ; –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ langdetect –∏–ª–∏ fasttext)."""
        # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫—É
        # –ó–¥–µ—Å—å ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        common_langs = {
            'en': ['the', 'and', 'is', 'in', 'to'],
            'ru': ['–∏', '–≤', '–Ω–µ', '–Ω–∞', '—Å'],
            'es': ['el', 'la', 'de', 'que', 'y'],
            'fr': ['le', 'de', 'et', '√†', 'les'],
        }
        text_lower = text.lower()
        for lang, words in common_langs.items():
            if any(word in text_lower for word in words):
                return lang
        return "unknown"

    def _generate_suggestions(self, label: SentimentLabel, confidence: float) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è empathetic_communicator."""
        suggestions = {"tone": "neutral", "urgency": "normal", "response_strategy": "standard"}

        if label in (SentimentLabel.VERY_NEGATIVE, SentimentLabel.NEGATIVE):
            suggestions.update({
                "tone": "apologetic",
                "urgency": "high" if confidence > 0.8 else "medium",
                "response_strategy": "clarify_and_reassure"
            })
        elif label == SentimentLabel.VERY_POSITIVE:
            suggestions.update({
                "tone": "enthusiastic",
                "urgency": "low",
                "response_strategy": "reinforce_and_offer_more"
            })

        return suggestions

    def analyze(self, text: str, job_id: Optional[str] = None, client_id: Optional[str] = None) -> SentimentResult:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —É–∂–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è.
        """
        if not self._initialized:
            raise RuntimeError("SentimentAnalyzer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        # –ö–ª—é—á –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        cache_key = f"sentiment:{hash(text)}"
        cached = self.cache.get(cache_key)
        if cached:
            logger.debug("üì¶ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
            return SentimentResult(**cached)

        # –û—Å–Ω–æ–≤–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞
        result = self._analyze_with_model(text, self._primary_model, "primary")

        # Fallback –ø—Ä–∏ –Ω–µ—É–¥–∞—á–µ
        if result is None and self._fallback_model:
            logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
            result = self._analyze_with_model(text, self._fallback_model, "fallback")

        # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π
        if result is None:
            logger.warning("‚ö†Ô∏è –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –í–æ–∑–≤—Ä–∞—â–∞–µ–º NEUTRAL –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            result = SentimentResult(
                label=SentimentLabel.NEUTRAL,
                confidence=0.5,
                language=self._detect_language(text),
                suggestions={"tone": "neutral", "urgency": "low", "response_strategy": "standard"}
            )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à (—Å TTL –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
        ttl = self.config.get("performance.cache.sentiment_ttl_seconds", default=3600)
        self.cache.set(cache_key, result.__dict__, ttl=ttl)

        # –ê—É–¥–∏—Ç
        self.audit_logger.log(
            action="sentiment_analysis",
            entity_type="message",
            entity_id=job_id or "unknown",
            metadata={
                "client_id": client_id,
                "text_preview": text[:100],
                "sentiment": result.label.name,
                "confidence": result.confidence
            }
        )

        return result

    def batch_analyze(self, texts: list[str]) -> list[SentimentResult]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)."""
        return [self.analyze(text) for text in texts]