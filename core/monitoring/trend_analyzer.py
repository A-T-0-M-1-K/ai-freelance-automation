# core/monitoring/trend_analyzer.py
"""
Trend Analyzer ‚Äî –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞, –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞
–≤—ã—è–≤–ª–µ–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö, –±–∏–∑–Ω–µ—Å- –∏ AI-–º–µ—Ç—Ä–∏–∫–∞—Ö.

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤–æ—Å—Ö–æ–¥—è—â–∏—Ö/–Ω–∏—Å—Ö–æ–¥—è—â–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤
- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–¥—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ, –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)
- –í—ã—è–≤–ª–µ–Ω–∏–µ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –∏ –∞–Ω–æ–º–∞–ª–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å anomaly_detection –∏ predictive_analytics
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ shared state

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –≥–∞—Ä–∞–Ω—Ç–∏–∏:
- –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –Ω–µ —Ö—Ä–∞–Ω–∏—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, —Ç–æ–ª—å–∫–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- –ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫, fallback-–º–µ—Ö–∞–Ω–∏–∑–º—ã
- –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç unified_config_manager –∏ metrics_collector
- –†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–ª–∞–≥–∏–Ω–æ–≤ –¥–ª—è –Ω–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
"""

import logging
import math
from typing import Dict, List, Optional, Tuple, Any, Callable
from datetime import datetime, timedelta
from collections import deque
import json

import numpy as np
from scipy import stats
from sklearn.linear_model import LinearRegression

from core.config.unified_config_manager import UnifiedConfigManager
from core.monitoring.metrics_collector import MetricsCollector
from core.dependency.service_locator import ServiceLocator

logger = logging.getLogger(__name__)


class TrendAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ —Å–∏—Å—Ç–µ–º—ã.
    –†–∞–±–æ—Ç–∞–µ—Ç –≤ —Ñ–æ–Ω–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑—ã –¥—Ä—É–≥–∏–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º.
    """

    def __init__(self, config_manager: Optional[UnifiedConfigManager] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Ç—Ä–µ–Ω–¥–æ–≤.

        Args:
            config_manager: –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –ï—Å–ª–∏ None ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ ServiceLocator.
        """
        self.config = config_manager or ServiceLocator.get("config")
        self.metrics_collector: MetricsCollector = ServiceLocator.get("metrics_collector")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        trend_config = self.config.get("monitoring.trend_analysis", {})
        self.window_size = trend_config.get("window_size_hours", 24)
        self.min_data_points = trend_config.get("min_data_points", 10)
        self.confidence_level = trend_config.get("confidence_level", 0.95)
        self.enabled_metrics = set(trend_config.get("enabled_metrics", [
            "jobs.fetched",
            "jobs.accepted",
            "revenue.daily",
            "ai.accuracy.average",
            "system.cpu.usage",
            "system.memory.usage"
        ]))

        # –í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤ –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–µ
        self._history: Dict[str, deque] = {
            metric: deque(maxlen=self._calculate_maxlen(metric)) for metric in self.enabled_metrics
        }

        # –ö—ç—à –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ (–¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏)
        self._last_forecast: Dict[str, Dict[str, Any]] = {}
        self._last_update: Dict[str, datetime] = {}

        logger.info(f"‚úÖ TrendAnalyzer initialized with window={self.window_size}h, "
                    f"metrics={list(self.enabled_metrics)}")

    def _calculate_maxlen(self, metric_name: str) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫."""
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç ‚Üí 12 —Ç–æ—á–µ–∫/—á–∞—Å
        points_per_hour = 12
        return max(self.min_data_points, self.window_size * points_per_hour)

    def ingest_metric(self, metric_name: str, value: float, timestamp: Optional[datetime] = None):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Ç–æ—á–∫—É –º–µ—Ç—Ä–∏–∫–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é.

        Args:
            metric_name: –∏–º—è –º–µ—Ç—Ä–∏–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'revenue.daily')
            value: —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            timestamp: –≤—Ä–µ–º—è —Ñ–∏–∫—Å–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —Å–µ–π—á–∞—Å)
        """
        if metric_name not in self.enabled_metrics:
            return  # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏

        if timestamp is None:
            timestamp = datetime.utcnow()

        self._history[metric_name].append((timestamp, value))
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫—ç—à –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        if metric_name in self._last_forecast:
            del self._last_forecast[metric_name]

    def analyze_trend(self, metric_name: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏:
            - trend: 'up', 'down', 'stable'
            - slope: –Ω–∞–∫–ª–æ–Ω –ª–∏–Ω–∏–∏ —Ç—Ä–µ–Ω–¥–∞
            - r_squared: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏
            - forecast_next: –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            - confidence_interval: [low, high]
            - seasonality_detected: bool
            - anomaly_risk: float [0..1]
        """
        if metric_name not in self.enabled_metrics:
            raise ValueError(f"Metric '{metric_name}' is not enabled for trend analysis")

        data = list(self._history[metric_name])
        if len(data) < self.min_data_points:
            return self._empty_result()

        timestamps, values = zip(*data)
        values = np.array(values, dtype=float)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ —á–∞—Å—ã —Å –Ω–∞—á–∞–ª–∞ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è
        start_time = min(timestamps)
        hours_since_start = np.array([
            (ts - start_time).total_seconds() / 3600.0 for ts in timestamps
        ]).reshape(-1, 1)

        # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
        model = LinearRegression()
        model.fit(hours_since_start, values)
        slope = float(model.coef_[0])
        r_squared = float(model.score(hours_since_start, values))

        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (+1 —á–∞—Å)
        next_hour = hours_since_start[-1] + 1
        forecast = float(model.predict(next_hour.reshape(1, -1))[0])

        # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π)
        residuals = values - model.predict(hours_since_start)
        std_err = np.std(residuals)
        t_val = stats.t.ppf((1 + self.confidence_level) / 2, len(values) - 2)
        margin = t_val * std_err * math.sqrt(1 + 1/len(values) + ((next_hour - np.mean(hours_since_start))**2) / np.sum((hours_since_start - np.mean(hours_since_start))**2))
        ci_low = forecast - margin
        ci_high = forecast + margin

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞
        if abs(slope) < 1e-6:
            trend = "stable"
        elif slope > 0:
            trend = "up"
        else:
            trend = "down"

        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∞–Ω–æ–º–∞–ª—å–Ω–æ–≥–æ —Ä–∏—Å–∫–∞ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Ç—Ä–µ–Ω–¥–∞)
        last_value = values[-1]
        predicted_last = float(model.predict(hours_since_start[-1].reshape(1, -1))[0])
        anomaly_risk = min(1.0, abs(last_value - predicted_last) / (std_err + 1e-6))

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ (–ø—Ä–æ—Å—Ç–∞—è: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ç–µ–º –∂–µ —á–∞—Å–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–Ω—è)
        seasonality_detected = False
        if len(values) >= 24 * 12:  # –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –¥–µ–Ω—å –¥–∞–Ω–Ω—ã—Ö
            try:
                current_hour = timestamps[-1].hour
                same_hour_values = [
                    v for ts, v in data[:-12] if ts.hour == current_hour
                ]
                if same_hour_values:
                    avg_same_hour = np.mean(same_hour_values)
                    if abs(last_value - avg_same_hour) > 2 * np.std(same_hour_values + [last_value]):
                        seasonality_detected = True
            except Exception as e:
                logger.debug(f"Seasonality check failed for {metric_name}: {e}")

        result = {
            "trend": trend,
            "slope": slope,
            "r_squared": r_squared,
            "forecast_next": forecast,
            "confidence_interval": [float(ci_low), float(ci_high)],
            "seasonality_detected": seasonality_detected,
            "anomaly_risk": float(anomaly_risk),
            "analyzed_at": datetime.utcnow().isoformat(),
            "data_points": len(values)
        }

        self._last_forecast[metric_name] = result
        self._last_update[metric_name] = datetime.utcnow()
        return result

    def get_cached_forecast(self, metric_name: str) -> Optional[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑, –µ—Å–ª–∏ –æ–Ω –∞–∫—Ç—É–∞–ª–µ–Ω (<5 –º–∏–Ω)."""
        if metric_name not in self._last_forecast:
            return None
        if datetime.utcnow() - self._last_update[metric_name] > timedelta(minutes=5):
            return None
        return self._last_forecast[metric_name]

    def _empty_result(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö."""
        return {
            "trend": "unknown",
            "slope": 0.0,
            "r_squared": 0.0,
            "forecast_next": 0.0,
            "confidence_interval": [0.0, 0.0],
            "seasonality_detected": False,
            "anomaly_risk": 0.0,
            "analyzed_at": datetime.utcnow().isoformat(),
            "data_points": 0
        }

    def export_state(self) -> Dict[str, Any]:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ –±—ç–∫–∞–ø–µ)."""
        serializable_history = {
            metric: [(ts.isoformat(), val) for ts, val in list(deq)]
            for metric, deq in self._history.items()
        }
        return {
            "history": serializable_history,
            "last_forecast": self._last_forecast,
            "last_update": {
                k: v.isoformat() for k, v in self._last_update.items()
            }
        }

    def restore_state(self, state: Dict[str, Any]):
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞."""
        try:
            for metric, data in state.get("history", {}).items():
                if metric in self._history:
                    self._history[metric].clear()
                    for ts_str, val in data:
                        self._history[metric].append((datetime.fromisoformat(ts_str), val))
            self._last_forecast = state.get("last_forecast", {})
            self._last_update = {
                k: datetime.fromisoformat(v) for k, v in state.get("last_update", {}).items()
            }
            logger.info("‚úÖ TrendAnalyzer state restored successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to restore TrendAnalyzer state: {e}")
            raise

    def get_all_trends(self) -> Dict[str, Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É."""
        return {
            metric: self.analyze_trend(metric) for metric in self.enabled_metrics
            if len(self._history[metric]) >= self.min_data_points
        }


# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ DI-–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
def register_trend_analyzer():
    """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –≤ ServiceLocator –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–∏—Å—Ç–µ–º—ã."""
    from core.dependency.service_locator import ServiceLocator
    if not ServiceLocator.has("trend_analyzer"):
        analyzer = TrendAnalyzer()
        ServiceLocator.register("trend_analyzer", analyzer)
        logger.debug("üìà TrendAnalyzer registered in ServiceLocator")