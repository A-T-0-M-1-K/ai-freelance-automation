import os
import psutil
import torch
import gc
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from pathlib import Path
import json


class MemoryOptimizer:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è —Å–∏—Å—Ç–µ–º —Å –ª–µ–Ω–∏–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π –ò–ò.
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
    - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAM/GPU
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –≤—ã–≥—Ä—É–∑–∫—É –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –º–æ–¥–µ–ª–µ–π
    - –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –ø–∞–º—è—Ç–∏
    - –î–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    """

    def __init__(self, config: Dict):
        self.config = config
        self.memory_history: List[Dict] = []
        self.model_usage_stats: Dict[str, Dict] = {}
        self.last_gc_time = datetime.utcnow()
        self.alert_thresholds = config.get("alert_thresholds", {
            "ram_warning": 80,  # %
            "ram_critical": 90,  # %
            "gpu_warning": 85,  # %
            "gpu_critical": 95,  # %
            "swap_warning": 50  # %
        })
        self.stats_file = Path("data/stats/memory_stats.json")
        self._load_history()

    def monitor_memory(self) -> Dict:
        """
        –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
        """
        # –°–∏—Å—Ç–µ–º–Ω–∞—è –ø–∞–º—è—Ç—å (RAM)
        ram = psutil.virtual_memory()
        swap = psutil.swap_memory()

        # GPU –ø–∞–º—è—Ç—å (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
        gpu_info = self._get_gpu_memory()

        # –ü–∞–º—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞ Python
        process = psutil.Process(os.getpid())
        process_memory = process.memory_info()

        timestamp = datetime.utcnow().isoformat()

        metrics = {
            "timestamp": timestamp,
            "ram": {
                "total_gb": ram.total / (1024 ** 3),
                "used_gb": ram.used / (1024 ** 3),
                "available_gb": ram.available / (1024 ** 3),
                "percent": ram.percent,
                "swap_percent": swap.percent
            },
            "gpu": gpu_info,
            "process": {
                "rss_gb": process_memory.rss / (1024 ** 3),
                "vms_gb": process_memory.vms / (1024 ** 3),
                "num_threads": process.num_threads()
            },
            "python_gc": {
                "garbage_count": len(gc.garbage),
                "collections": gc.get_count()
            }
        }

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.memory_history.append(metrics)

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π (> 24 —á–∞—Å–∞)
        cutoff = datetime.utcnow() - timedelta(hours=24)
        self.memory_history = [
            m for m in self.memory_history
            if datetime.fromisoformat(m["timestamp"]) > cutoff
        ]

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –¥–∏—Å–∫
        self._save_history()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤
        self._check_memory_alerts(metrics)

        return metrics

    def _get_gpu_memory(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ GPU"""
        if not torch.cuda.is_available():
            return {"available": False, "devices": []}

        devices = []
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            mem_info = torch.cuda.mem_get_info(i)

            total = props.total_memory
            free = mem_info[0]
            used = total - free

            devices.append({
                "id": i,
                "name": props.name,
                "total_gb": total / (1024 ** 3),
                "used_gb": used / (1024 ** 3),
                "free_gb": free / (1024 ** 3),
                "percent": (used / total) * 100,
                "temperature": self._get_gpu_temperature(i)
            })

        return {
            "available": True,
            "devices": devices,
            "active_device": torch.cuda.current_device()
        }

    def _get_gpu_temperature(self, device_id: int) -> Optional[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã GPU (Linux —Ç–æ–ª—å–∫–æ)"""
        try:
            # –î–ª—è NVIDIA —á–µ—Ä–µ–∑ nvidia-smi
            import subprocess
            result = subprocess.run(
                ['nvidia-smi', '--query-gpu=temperature.gpu', '--format=csv,noheader,nounits'],
                capture_output=True,
                text=True,
                timeout=2
            )
            if result.returncode == 0:
                temps = [float(t.strip()) for t in result.stdout.strip().split('\n')]
                return temps[device_id] if device_id < len(temps) else None
        except:
            pass
        return None

    def _check_memory_alerts(self, metrics: Dict):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª–µ—Ä—Ç–æ–≤"""
        alerts = []

        # RAM –∞–ª–µ—Ä—Ç—ã
        if metrics["ram"]["percent"] > self.alert_thresholds["ram_critical"]:
            alerts.append({
                "level": "critical",
                "type": "ram",
                "message": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RAM: {metrics['ram']['percent']:.1f}%",
                "timestamp": metrics["timestamp"]
            })
        elif metrics["ram"]["percent"] > self.alert_thresholds["ram_warning"]:
            alerts.append({
                "level": "warning",
                "type": "ram",
                "message": f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RAM: {metrics['ram']['percent']:.1f}%",
                "timestamp": metrics["timestamp"]
            })

        # GPU –∞–ª–µ—Ä—Ç—ã
        if metrics["gpu"]["available"]:
            for device in metrics["gpu"]["devices"]:
                if device["percent"] > self.alert_thresholds["gpu_critical"]:
                    alerts.append({
                        "level": "critical",
                        "type": "gpu",
                        "device_id": device["id"],
                        "message": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU {device['id']}: {device['percent']:.1f}%",
                        "temperature": device.get("temperature"),
                        "timestamp": metrics["timestamp"]
                    })
                elif device["percent"] > self.alert_thresholds["gpu_warning"]:
                    alerts.append({
                        "level": "warning",
                        "type": "gpu",
                        "device_id": device["id"],
                        "message": f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU {device['id']}: {device['percent']:.1f}%",
                        "temperature": device.get("temperature"),
                        "timestamp": metrics["timestamp"]
                    })

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤
        for alert in alerts:
            self._handle_alert(alert)

    def _handle_alert(self, alert: Dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–ª–µ—Ä—Ç–∞ ‚Äî –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è"""
        print(f"[{alert['level'].upper()}] {alert['message']}")

        # –ó–∞–ø–∏—Å—å –≤ –ª–æ–≥ –∞–ª–µ—Ä—Ç–æ–≤
        alert_log = Path("logs/alerts/memory_alerts.log")
        alert_log.parent.mkdir(parents=True, exist_ok=True)

        with open(alert_log, 'a') as f:
            f.write(f"{alert['timestamp']} | {alert['level']} | {alert['type']} | {alert['message']}\n")

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∞–ª–µ—Ä—Ç–æ–≤
        if alert["level"] == "critical":
            if alert["type"] == "ram":
                self._emergency_ram_optimization()
            elif alert["type"] == "gpu":
                self._emergency_gpu_optimization(alert.get("device_id", 0))

    def _emergency_ram_optimization(self):
        """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAM"""
        print("‚ö†Ô∏è  –ó–∞–ø—É—Å–∫ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ RAM...")

        # 1. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
        gc.collect()

        # 2. –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π PyTorch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # 3. –í—ã–≥—Ä—É–∑–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ò–ò
        from core.ai_management.lazy_model_loader import LazyModelLoader
        loader = LazyModelLoader.get_instance()
        unloaded = loader.unload_inactive_models(max_age_minutes=5)
        print(f"   üì¶ –í—ã–≥—Ä—É–∂–µ–Ω–æ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {len(unloaded)}")

        # 4. –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –¥–∞–Ω–Ω—ã—Ö
        from core.performance.intelligent_cache_system import IntelligentCacheSystem
        cache = IntelligentCacheSystem.get_instance()
        freed = cache.clear_low_priority_cache()
        print(f"   üóëÔ∏è  –û—á–∏—â–µ–Ω–æ –∫—ç—à–∞: {freed / (1024 ** 2):.2f} MB")

        print("‚úÖ –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è RAM –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def _emergency_gpu_optimization(self, device_id: int):
        """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU"""
        print(f"‚ö†Ô∏è  –ó–∞–ø—É—Å–∫ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ GPU {device_id}...")

        # 1. –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ CUDA
        torch.cuda.empty_cache()

        # 2. –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤ –Ω–∞ CPU
        # (–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)

        # 3. –°–Ω–∏–∂–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
        # torch.set_float32_matmul_precision('medium')

        print(f"‚úÖ –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è GPU {device_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def _save_history(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫ –Ω–∞ –¥–∏—Å–∫"""
        if not self.stats_file.parent.exists():
            self.stats_file.parent.mkdir(parents=True, exist_ok=True)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 1000 –∑–∞–ø–∏—Å–µ–π
        history_to_save = self.memory_history[-1000:]

        with open(self.stats_file, 'w') as f:
            json.dump({
                "last_updated": datetime.utcnow().isoformat(),
                "history": history_to_save
            }, f, indent=2)

    def _load_history(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫ —Å –¥–∏—Å–∫–∞"""
        if self.stats_file.exists():
            try:
                with open(self.stats_file) as f:
                    data = json.load(f)
                    self.memory_history = data.get("history", [])
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ –ø–∞–º—è—Ç–∏: {e}")

    def get_memory_recommendations(self) -> List[str]:
        """
        –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
        """
        if len(self.memory_history) < 10:
            return ["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"]

        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
        recent = self.memory_history[-10:]
        avg_ram = sum(m["ram"]["percent"] for m in recent) / len(recent)
        avg_gpu = 0
        gpu_devices = 0

        if recent[0]["gpu"]["available"]:
            for m in recent:
                for dev in m["gpu"]["devices"]:
                    avg_gpu += dev["percent"]
                    gpu_devices += 1
            avg_gpu = avg_gpu / gpu_devices if gpu_devices > 0 else 0

        recommendations = []

        if avg_ram > 85:
            recommendations.append("‚ö†Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RAM > 85% ‚Äî —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏")
            recommendations.append("üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
            recommendations.append("üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –í–∫–ª—é—á–∏—Ç–µ –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π")

        if avg_gpu > 80:
            recommendations.append("‚ö†Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU > 80% ‚Äî —Ä–∏—Å–∫ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –ø–∏–∫–æ–≤—ã—Ö –Ω–∞–≥—Ä—É–∑–∫–∞—Ö")
            recommendations.append("üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π (int8/float16)")
            recommendations.append("üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –í–Ω–µ–¥—Ä–∏—Ç–µ –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ —ç—Ç–∞–ø—ã")

        # –ê–Ω–∞–ª–∏–∑ —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏ (–º–æ–Ω–æ—Ç–æ–Ω–Ω—ã–π —Ä–æ—Å—Ç)
        if len(self.memory_history) >= 30:
            first_10 = self.memory_history[-30:-20]
            last_10 = self.memory_history[-10:]
            first_avg = sum(m["ram"]["percent"] for m in first_10) / 10
            last_avg = sum(m["ram"]["percent"] for m in last_10) / 10

            if last_avg - first_avg > 5:  # –†–æ—Å—Ç > 5% –∑–∞ –ø–µ—Ä–∏–æ–¥
                recommendations.append("üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —É—Ç–µ—á–∫–∞ –ø–∞–º—è—Ç–∏ ‚Äî —Ä–æ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ {:.1f}%".format(
                    last_avg - first_avg))
                recommendations.append("üîç –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ —á–µ—Ä–µ–∑ memory_profiler")

        return recommendations if recommendations else ["‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ –Ω–æ—Ä–º–µ"]

    def generate_memory_report(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–∞–º—è—Ç–∏.
        """
        metrics = self.monitor_memory()
        recommendations = self.get_memory_recommendations()

        report = f"""
–û—Ç—á—ë—Ç –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–∞–º—è—Ç–∏
–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {metrics['timestamp']}
{'=' * 60}

üìä –û–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å (RAM)
   –í—Å–µ–≥–æ:    {metrics['ram']['total_gb']:.2f} GB
   –ò—Å–ø–æ–ª—å–∑.: {metrics['ram']['used_gb']:.2f} GB ({metrics['ram']['percent']:.1f}%)
   –°–≤–æ–±–æ–¥–Ω–æ: {metrics['ram']['available_gb']:.2f} GB
   Swap:     {metrics['ram']['swap_percent']:.1f}%

{'GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω' if not metrics['gpu']['available'] else ''}
"""

        if metrics['gpu']['available']:
            report += "\nüéÆ –í–∏–¥–µ–æ–ø–∞–º—è—Ç—å (GPU)\n"
            for dev in metrics['gpu']['devices']:
                temp_info = f" ({dev['temperature']}¬∞C)" if dev.get('temperature') else ""
                report += f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {dev['id']} ({dev['name']}){temp_info}:\n"
                report += f"      –ò—Å–ø–æ–ª—å–∑.: {dev['used_gb']:.2f} GB ({dev['percent']:.1f}%)\n"
                report += f"      –°–≤–æ–±–æ–¥–Ω–æ: {dev['free_gb']:.2f} GB\n"

        report += f"\nüêç –ü–∞–º—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞ Python\n"
        report += f"   RSS:  {metrics['process']['rss_gb']:.2f} GB\n"
        report += f"   VMS:  {metrics['process']['vms_gb']:.2f} GB\n"
        report += f"   –ü–æ—Ç–æ–∫–∏: {metrics['process']['num_threads']}\n"

        report += f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
        for i, rec in enumerate(recommendations, 1):
            report += f"   {i}. {rec}\n"

        return report


# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ Prometheus
def setup_prometheus_memory_metrics():
    """
    –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç—Ä–∏–∫ –ø–∞–º—è—Ç–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Prometheus.
    """
    try:
        from prometheus_client import Gauge, CollectorRegistry, push_to_gateway

        registry = CollectorRegistry()

        ram_percent = Gauge('system_ram_percent', 'RAM usage percent', registry=registry)
        gpu_percent = Gauge('system_gpu_percent', 'GPU usage percent', registry=registry)
        process_rss = Gauge('process_rss_bytes', 'Process RSS memory in bytes', registry=registry)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        optimizer = MemoryOptimizer(config={})
        metrics = optimizer.monitor_memory()

        ram_percent.set(metrics['ram']['percent'])
        process_rss.set(metrics['process']['rss_gb'] * (1024 ** 3))

        if metrics['gpu']['available'] and metrics['gpu']['devices']:
            gpu_percent.set(metrics['gpu']['devices'][0]['percent'])

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Pushgateway (–¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á)
        push_to_gateway('localhost:9091', job='ai_freelance', registry=registry)

        print("‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –ø–∞–º—è—Ç–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ Prometheus")

    except ImportError:
        print("‚ÑπÔ∏è  Prometheus client –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫ —ç–∫—Å–ø–æ—Ä—Ç–∞ –º–µ—Ç—Ä–∏–∫")
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –º–µ—Ç—Ä–∏–∫ –≤ Prometheus: {e}")