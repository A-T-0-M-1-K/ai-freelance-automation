# AI_FREELANCE_AUTOMATION/core/monitoring/resource_optimizer.py
"""
Resource Optimizer ‚Äî –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π –Ω–∞–≥—Ä—É–∑–∫–∏, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ –∑–∞–¥–∞—á –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç predictive_analytics.
–¶–µ–ª—å: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–µ—Ä–∂–∫–∏ –∏ –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏.
"""

import asyncio
import logging
import psutil
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from datetime import datetime, timedelta

from core.config.config_manager import UnifiedConfigManager
from core.monitoring.metrics_collector import MetricsCollector
from core.monitoring.threshold_manager import ThresholdManager
from core.ai_management.intelligent_model_manager import IntelligentModelManager
from core.dependency.service_locator import ServiceLocator

logger = logging.getLogger("ResourceOptimizer")


@dataclass
class ResourceAllocation:
    cpu_cores: int
    memory_mb: int
    gpu_memory_mb: Optional[int] = None
    io_priority: int = 1  # 1-5, –≥–¥–µ 5 ‚Äî highest


class ResourceOptimizer:
    """
    –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Ä–µ—Å—É—Ä—Å–æ–≤. –†–∞–±–æ—Ç–∞–µ—Ç –≤ —Ñ–æ–Ω–µ, –∞–¥–∞–ø—Ç–∏—Ä—É—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ CPU, RAM, GPU
    –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ –∑–∞–¥–∞—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è vs –∫–æ–ø–∏—Ä–∞–π—Ç–∏–Ω–≥).
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å:
      - MetricsCollector (–¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö)
      - ThresholdManager (–¥–ª—è —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –ø–æ—Ä–æ–≥–∏)
      - ModelManager (–¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π)
    """

    def __init__(
        self,
        config_manager: UnifiedConfigManager,
        metrics_collector: MetricsCollector,
        threshold_manager: ThresholdManager,
        model_manager: IntelligentModelManager,
    ):
        self.config = config_manager.get_section("performance")
        self.metrics = metrics_collector
        self.thresholds = threshold_manager
        self.model_manager = model_manager
        self._running = False
        self._last_optimization = datetime.min
        self._optimization_interval = self.config.get("resource_optimization_interval_sec", 30)
        self._cooldown_period = timedelta(seconds=self.config.get("optimization_cooldown_sec", 60))

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
        self._max_cpu_percent = self.config.get("max_cpu_usage_percent", 85)
        self._max_memory_percent = self.config.get("max_memory_usage_percent", 80)
        self._min_free_memory_mb = self.config.get("min_free_memory_mb", 1024)

        logger.info("Intialized ResourceOptimizer with config: %s", {
            "interval_sec": self._optimization_interval,
            "max_cpu%": self._max_cpu_percent,
            "max_mem%": self._max_memory_percent,
        })

    async def start(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞."""
        if self._running:
            logger.warning("ResourceOptimizer —É–∂–µ –∑–∞–ø—É—â–µ–Ω.")
            return
        self._running = True
        logger.info("üöÄ –ó–∞–ø—É—â–µ–Ω ResourceOptimizer.")
        while self._running:
            try:
                await self._optimize_cycle()
                await asyncio.sleep(self._optimization_interval)
            except Exception as e:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ ResourceOptimizer: %s", e, exc_info=True)
                await asyncio.sleep(5)  # –∏–∑–±–µ–∂–∞—Ç—å —Å–ø–∞–º–∞

    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞."""
        self._running = False
        logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ResourceOptimizer.")

    async def _optimize_cycle(self):
        """–û–¥–∏–Ω —Ü–∏–∫–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        now = datetime.now()
        if now - self._last_optimization < self._cooldown_period:
            return  # —Å–æ–±–ª—é–¥–∞–µ–º cooldown

        try:
            system_load = self._get_system_load()
            active_jobs = await self._get_active_job_priorities()

            # –ê–Ω–∞–ª–∏–∑: –µ—Å—Ç—å –ª–∏ —Ä–∏—Å–∫ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏?
            if self._is_overloaded(system_load):
                logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º—ã. –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
                await self._apply_load_shedding(active_jobs)
            else:
                # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º: –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞
                await self._balance_resources(active_jobs, system_load)

            self._last_optimization = now
            logger.debug("‚úÖ –¶–∏–∫–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à—ë–Ω.")

        except Exception as e:
            logger.exception("üí• –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ _optimize_cycle: %s", e)

    def _get_system_load(self) -> Dict[str, Any]:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤."""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk_io = psutil.disk_io_counters()
        net_io = psutil.net_io_counters()

        return {
            "cpu_percent": cpu_percent,
            "memory_percent": memory.percent,
            "memory_available_mb": memory.available // (1024 * 1024),
            "disk_read_mb": disk_io.read_bytes // (1024 * 1024) if disk_io else 0,
            "disk_write_mb": disk_io.write_bytes // (1024 * 1024) if disk_io else 0,
            "net_sent_mb": net_io.bytes_sent // (1024 * 1024) if net_io else 0,
            "net_recv_mb": net_io.bytes_recv // (1024 * 1024) if net_io else 0,
        }

    def _is_overloaded(self, load: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏ –ø–æ—Ä–æ–≥–∏ –Ω–∞–≥—Ä—É–∑–∫–∏."""
        return (
            load["cpu_percent"] > self._max_cpu_percent or
            load["memory_percent"] > self._max_memory_percent or
            load["memory_available_mb"] < self._min_free_memory_mb
        )

    async def _get_active_job_priorities(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á —Å –∏—Ö –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏.
        –§–æ—Ä–º–∞—Ç: [{"job_id": str, "priority": int (1-10), "type": str, "deadline": datetime}]
        """
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ ServiceLocator –∏–ª–∏ JobRegistry
        job_service = ServiceLocator.get_service("job_registry")
        if not job_service:
            logger.warning("Job registry –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á.")
            return []

        try:
            return await job_service.get_active_jobs_with_priority()
        except Exception as e:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏: %s", e)
            return []

    async def _apply_load_shedding(self, jobs: List[Dict[str, Any]]):
        """–°–Ω–∏–∂–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É: –ø—Ä–∏–æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–∏–∑–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏."""
        logger.info("üìâ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ load shedding –¥–ª—è %d –∑–∞–¥–∞—á.", len(jobs))
        low_priority_jobs = [j for j in jobs if j["priority"] <= 3]

        for job in low_priority_jobs:
            try:
                logger.info("‚è∏Ô∏è –ü—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ %s (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)", job["job_id"])
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å workflow_orchestrator.pause(job_id)
                orchestrator = ServiceLocator.get_service("workflow_orchestrator")
                if orchestrator:
                    await orchestrator.pause_task(job["job_id"])
            except Exception as e:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–¥–∞—á—É %s: %s", job["job_id"], e)

        # –í—ã–≥—Ä—É–∑–∫–∞ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö AI-–º–æ–¥–µ–ª–µ–π
        await self.model_manager.unload_low_priority_models()

    async def _balance_resources(self, jobs: List[Dict[str, Any]], load: Dict[str, Any]):
        """–ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç —Ä–µ—Å—É—Ä—Å—ã –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏."""
        # –ü—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ –º–Ω–æ–≥–æ –∑–∞–¥–∞—á —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ ‚Äî –≤—ã–¥–µ–ª–∏—Ç—å –±–æ–ª—å—à–µ CPU/GPU
        transcription_count = sum(1 for j in jobs if j["type"] == "transcription")
        translation_count = sum(1 for j in jobs if j["type"] == "translation")

        if transcription_count > 0:
            # Whisper —Ç—Ä–µ–±—É–µ—Ç CPU/GPU ‚Äî —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
            await self.model_manager.ensure_model_loaded("whisper-medium")

        if translation_count > 0:
            await self.model_manager.ensure_model_loaded("nllb-200")

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—É–ª–æ–≤ –ø–æ—Ç–æ–∫–æ–≤ (–≤ –±—É–¥—É—â–µ–º ‚Äî —á–µ—Ä–µ–∑ auto_scaler)
        logger.debug(
            "‚öñÔ∏è –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è=%d, –ø–µ—Ä–µ–≤–æ–¥=%d, CPU=%.1f%%, RAM=%.1f%%",
            transcription_count, translation_count,
            load["cpu_percent"], load["memory_percent"]
        )

    def get_current_allocation(self) -> ResourceAllocation:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏/API)."""
        load = self._get_system_load()
        total_cpu = psutil.cpu_count()
        allocated_cpu = min(total_cpu, max(1, int(total_cpu * (load["cpu_percent"] / 100))))
        memory_total = psutil.virtual_memory().total // (1024 * 1024)
        allocated_mem = memory_total - load["memory_available_mb"]

        return ResourceAllocation(
            cpu_cores=allocated_cpu,
            memory_mb=allocated_mem,
            gpu_memory_mb=None,  # TODO: –¥–æ–±–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ nvidia-ml-py –∏–ª–∏ –∞–Ω–∞–ª–æ–≥
            io_priority=3
        )