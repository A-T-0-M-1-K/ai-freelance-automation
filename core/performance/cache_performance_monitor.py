# AI_FREELANCE_AUTOMATION/core/performance/cache_performance_monitor.py
"""
–ú–æ–¥—É–ª—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à-—Å–∏—Å—Ç–µ–º—ã.
–°–ª–µ–¥–∏—Ç –∑–∞ hit rate, latency, —Ä–∞–∑–º–µ—Ä–æ–º –∫—ç—à–∞, —á–∞—Å—Ç–æ—Ç–æ–π –ø—Ä–æ–º–∞—Ö–æ–≤,
–æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é –∏ –∏–Ω–∏—Ü–∏–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∏–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ.
"""

import asyncio
import logging
import time
from typing import Dict, Any, Optional
from dataclasses import dataclass
from collections import deque

from core.monitoring.metrics_collector import MetricsCollector
from core.security.audit_logger import AuditLogger
from core.dependency.service_locator import ServiceLocator


@dataclass
class CacheMetrics:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –∫—ç—à–∞."""
    timestamp: float
    hit_rate: float
    miss_rate: float
    avg_get_latency_ms: float
    avg_set_latency_ms: float
    cache_size_bytes: int
    evictions_count: int
    memory_usage_percent: float


class CachePerformanceMonitor:
    """
    –ù–∞–±–ª—é–¥–∞—Ç–µ–ª—å –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∫—ç—à-—Å–∏—Å—Ç–µ–º—ã.
    –†–∞–±–æ—Ç–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥,
    —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å –ø–æ—Ä–æ–≥–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.logger = logging.getLogger("CachePerformanceMonitor")
        self.config = config or self._load_default_config()
        self.metrics_history: deque = deque(maxlen=self.config.get("history_window", 100))
        self.is_running = False
        self._monitor_task: Optional[asyncio.Task] = None

        # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Service Locator (–∏–∑–±–µ–≥–∞–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤)
        self.metrics_collector: MetricsCollector = ServiceLocator.get("metrics_collector")
        self.audit_logger: AuditLogger = ServiceLocator.get("audit_logger")

        self.logger.info("Intialized CachePerformanceMonitor with config: %s", self.config)

    def _load_default_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞."""
        return {
            "monitoring_interval_sec": 10,
            "history_window": 100,
            "thresholds": {
                "min_hit_rate": 0.75,
                "max_avg_latency_ms": 50.0,
                "max_memory_usage_percent": 85.0,
                "max_eviction_rate_per_min": 100
            },
            "enable_anomaly_detection": True,
            "auto_optimize_on_degradation": True
        }

    async def start_monitoring(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ —Ñ–æ–Ω–µ."""
        if self.is_running:
            self.logger.warning("Monitoring already running.")
            return

        self.is_running = True
        self._monitor_task = asyncio.create_task(self._monitoring_loop())
        self.logger.info("‚úÖ Cache performance monitoring started.")

    async def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥."""
        if not self.is_running:
            return

        self.is_running = False
        if self._monitor_task:
            self._monitor_task.cancel()
            try:
                await self._monitor_task
            except asyncio.CancelledError:
                pass
        self.logger.info("‚èπÔ∏è Cache performance monitoring stopped.")

    async def _monitoring_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫."""
        while self.is_running:
            try:
                metrics = await self._collect_current_metrics()
                self.metrics_history.append(metrics)
                await self._report_metrics(metrics)
                await self._analyze_and_react(metrics)
            except Exception as e:
                self.logger.error("‚ùå Error in cache monitoring loop: %s", e, exc_info=True)
                await self.audit_logger.log_security_event(
                    event_type="cache_monitoring_failure",
                    details={"error": str(e)},
                    severity="high"
                )
            finally:
                await asyncio.sleep(self.config["monitoring_interval_sec"])

    async def _collect_current_metrics(self) -> CacheMetrics:
        """–°–æ–±–∏—Ä–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç –∫—ç—à-—Å–∏—Å—Ç–µ–º—ã."""
        cache_system = ServiceLocator.get("intelligent_cache_system")
        if not cache_system:
            raise RuntimeError("IntelligentCacheSystem not found in ServiceLocator")

        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∫—ç—à-—Å–∏—Å—Ç–µ–º—ã
        stats = await cache_system.get_performance_stats()

        now = time.time()
        return CacheMetrics(
            timestamp=now,
            hit_rate=stats.get("hit_rate", 0.0),
            miss_rate=1.0 - stats.get("hit_rate", 0.0),
            avg_get_latency_ms=stats.get("avg_get_latency_ms", 0.0),
            avg_set_latency_ms=stats.get("avg_set_latency_ms", 0.0),
            cache_size_bytes=stats.get("cache_size_bytes", 0),
            evictions_count=stats.get("evictions_count", 0),
            memory_usage_percent=stats.get("memory_usage_percent", 0.0)
        )

    async def _report_metrics(self, metrics: CacheMetrics):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        self.metrics_collector.record("cache.hit_rate", metrics.hit_rate)
        self.metrics_collector.record("cache.miss_rate", metrics.miss_rate)
        self.metrics_collector.record("cache.avg_get_latency_ms", metrics.avg_get_latency_ms)
        self.metrics_collector.record("cache.avg_set_latency_ms", metrics.avg_set_latency_ms)
        self.metrics_collector.record("cache.size_bytes", metrics.cache_size_bytes)
        self.metrics_collector.record("cache.evictions_total", metrics.evictions_count)
        self.metrics_collector.record("cache.memory_usage_percent", metrics.memory_usage_percent)

    async def _analyze_and_react(self, metrics: CacheMetrics):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã."""
        thresholds = self.config["thresholds"]
        issues = []

        if metrics.hit_rate < thresholds["min_hit_rate"]:
            issues.append(f"Low hit rate: {metrics.hit_rate:.2%} < {thresholds['min_hit_rate']:.2%}")

        if metrics.avg_get_latency_ms > thresholds["max_avg_latency_ms"]:
            issues.append(f"High GET latency: {metrics.avg_get_latency_ms:.2f}ms > {thresholds['max_avg_latency_ms']}ms")

        if metrics.memory_usage_percent > thresholds["max_memory_usage_percent"]:
            issues.append(f"High memory usage: {metrics.memory_usage_percent:.2f}% > {thresholds['max_memory_usage_percent']}%")

        # –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤—ã—Ç–µ—Å–Ω–µ–Ω–∏–π (evictions)
        if len(self.metrics_history) >= 2:
            prev = self.metrics_history[-2]
            current = metrics
            time_diff_sec = current.timestamp - prev.timestamp
            if time_diff_sec > 0:
                eviction_rate = (current.evictions_count - prev.evictions_count) / (time_diff_sec / 60)
                if eviction_rate > thresholds["max_eviction_rate_per_min"]:
                    issues.append(f"High eviction rate: {eviction_rate:.1f}/min > {thresholds['max_eviction_rate_per_min']}/min")

        if issues:
            self.logger.warning("‚ö†Ô∏è Cache performance degradation detected: %s", "; ".join(issues))
            await self.audit_logger.log_security_event(
                event_type="cache_performance_degradation",
                details={"issues": issues, "metrics": metrics.__dict__},
                severity="medium"
            )

            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–∫—Ü–∏—è
            if self.config.get("auto_optimize_on_degradation", False):
                await self._trigger_optimization(issues)

    async def _trigger_optimization(self, issues: list):
        """–ò–Ω–∏—Ü–∏–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∫—ç—à-—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏."""
        try:
            strategy_selector = ServiceLocator.get("strategy_selector")
            if strategy_selector:
                self.logger.info("üîÑ Triggering cache strategy optimization due to: %s", issues)
                await strategy_selector.optimize_strategy(reasons=issues)
            else:
                self.logger.warning("StrategySelector not available for optimization.")
        except Exception as e:
            self.logger.error("Failed to trigger cache optimization: %s", e)
            await self.audit_logger.log_security_event(
                event_type="cache_optimization_failure",
                details={"error": str(e)},
                severity="medium"
            )

    def get_latest_metrics(self) -> Optional[CacheMetrics]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏/UI)."""
        return self.metrics_history[-1] if self.metrics_history else None

    def get_health_status(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è –∫—ç—à-—Å–∏—Å—Ç–µ–º—ã."""
        latest = self.get_latest_metrics()
        if not latest:
            return {"status": "unknown", "reason": "no metrics collected yet"}

        thresholds = self.config["thresholds"]
        healthy = (
            latest.hit_rate >= thresholds["min_hit_rate"] and
            latest.avg_get_latency_ms <= thresholds["max_avg_latency_ms"] and
            latest.memory_usage_percent <= thresholds["max_memory_usage_percent"]
        )

        return {
            "status": "healthy" if healthy else "degraded",
            "last_update": latest.timestamp,
            "hit_rate": latest.hit_rate,
            "latency_ms": latest.avg_get_latency_ms,
            "memory_usage_percent": latest.memory_usage_percent
        }