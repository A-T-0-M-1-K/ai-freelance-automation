# AI_FREELANCE_AUTOMATION/core/learning/feedback_analyzer.py

"""
Feedback Analyzer ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π —Ñ–∏–¥–±—ç–∫ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã.
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É—Å–ø–µ—Ö–∞/–ø—Ä–æ–≤–∞–ª–∞, –æ–±–Ω–æ–≤–ª—è–µ—Ç –∑–Ω–∞–Ω–∏—è, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞.
"""

import json
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
from datetime import datetime

from core.dependency.service_locator import ServiceLocator
from core.config.unified_config_manager import UnifiedConfigManager
from core.learning.pattern_extractor import PatternExtractor
from core.learning.knowledge_base import KnowledgeBase
from core.monitoring.intelligent_monitoring_system import AlertLevel

logger = logging.getLogger("FeedbackAnalyzer")


class FeedbackAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ñ–æ—Ä–º—ã –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤:
    - –û—Ç–∑—ã–≤—ã –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞
    - –°–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç–∞—Ö (–Ω–µ—è–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã)
    - –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–∫–∞–∑—ã / –æ—Ç–∫–∞–∑—ã
    - –û—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)

    –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è:
    - –û–±–Ω–æ–≤–ª–µ–Ω–∏—è KnowledgeBase
    - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ DecisionEngine
    - –ö–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ Communicator'–∞
    """

    def __init__(
            self,
            config: Optional[UnifiedConfigManager] = None,
            knowledge_base: Optional[KnowledgeBase] = None,
            pattern_extractor: Optional[PatternExtractor] = None,
    ):
        self.config = config or ServiceLocator.get_service("config")
        self.knowledge_base = knowledge_base or ServiceLocator.get_service("knowledge_base")
        self.pattern_extractor = pattern_extractor or ServiceLocator.get_service("pattern_extractor")

        self.data_dir = Path(self.config.get("data.feedback_dir", "data/feedback"))
        self.data_dir.mkdir(parents=True, exist_ok=True)

        self._load_feedback_index()
        logger.info("‚úÖ FeedbackAnalyzer initialized.")

    def _load_feedback_index(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤."""
        index_path = self.data_dir / "feedback_index.json"
        if index_path.exists():
            try:
                with open(index_path, "r", encoding="utf-8") as f:
                    self.processed_feedback_ids = set(json.load(f))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to load feedback index: {e}. Recreating.")
                self.processed_feedback_ids = set()
        else:
            self.processed_feedback_ids = set()

    def _save_feedback_index(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω–¥–µ–∫—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤."""
        index_path = self.data_dir / "feedback_index.json"
        try:
            with open(index_path, "w", encoding=" utf-8") as f:
                json.dump(list(self.processed_feedback_ids), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"üí• Failed to save feedback index: {e}")

    def analyze_job_feedback(self, job_id: str, feedback_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∏–¥–±—ç–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∑–∞–∫–∞–∑—É.

        –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ feedback_data:
        {
            "client_id": "str",
            "rating": 1-5 (optional),
            "text": "—Å—Ç—Ä–æ–∫–∞ –æ—Ç–∑—ã–≤–∞ (optional)",
            "reordered": bool,
            "messages_context": [{"role": "...", "content": "..."}],
            "delivered_on_time": bool,
            "revision_count": int
        }
        """
        if not job_id or not isinstance(feedback_data, dict):
            logger.error("‚ùå Invalid input to analyze_job_feedback")
            raise ValueError("job_id and feedback_data must be valid")

        feedback_id = f"{job_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
        if feedback_id in self.processed_feedback_ids:
            logger.debug(f"‚è≠Ô∏è Feedback {feedback_id} already processed. Skipping.")
            return {}

        logger.info(f"üîç Analyzing feedback for job {job_id}")

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        analysis = self._extract_feedback_signals(feedback_data)
        analysis["job_id"] = job_id
        analysis["client_id"] = feedback_data.get("client_id")
        analysis["timestamp"] = datetime.utcnow().isoformat()

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
        self._persist_analysis(feedback_id, analysis)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π
        self._update_knowledge_base(analysis)

        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ –∏–Ω–¥–µ–∫—Å–µ
        self.processed_feedback_ids.add(feedback_id)
        self._save_feedback_index()

        logger.info(f"‚úÖ Feedback analysis completed for job {job_id}")
        return analysis

    def _extract_feedback_signals(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ —Ñ–∏–¥–±—ç–∫–∞."""
        signals = {}

        # –Ø–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        signals["explicit_rating"] = data.get("rating")
        signals["on_time_delivery"] = data.get("delivered_on_time", True)
        signals["revision_count"] = data.get("revision_count", 0)
        signals["reordered"] = data.get("reordered", False)

        # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
        text = data.get("text", "")
        if text:
            sentiment = self._analyze_sentiment(text)
            signals["sentiment_score"] = sentiment["score"]
            signals["sentiment_label"] = sentiment["label"]
            signals["keywords"] = sentiment.get("keywords", [])
        else:
            signals["sentiment_score"] = 0.0
            signals["sentiment_label"] = "neutral"

        # –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        messages = data.get("messages_context", [])
        if messages:
            dialogue_patterns = self.pattern_extractor.extract_dialogue_patterns(messages)
            signals["dialogue_patterns"] = dialogue_patterns

        # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —É—Å–ø–µ—Ö–∞ (0.0‚Äì1.0)
        success_score = self._calculate_success_score(signals)
        signals["success_score"] = success_score

        # –ê–ª–µ—Ä—Ç –ø—Ä–∏ –Ω–∏–∑–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ
        if success_score < 0.3:
            from core.monitoring.intelligent_monitoring_system import IntelligentMonitoringSystem
            monitor = ServiceLocator.get_service("monitoring")
            monitor.log_alert(
                level=AlertLevel.WARNING,
                source="FeedbackAnalyzer",
                message=f"Low success score ({success_score:.2f}) for job feedback",
                context={"signals": signals}
            )

        return signals

    def _analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ (stub; –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ ‚Äî –≤—ã–∑–æ–≤ AI-—Å–µ—Ä–≤–∏—Å–∞)."""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: –≤—ã–∑–æ–≤ ai_services/sentiment_analysis –∏–ª–∏ –≤–Ω–µ—à–Ω–µ–≥–æ API
        # –ó–¥–µ—Å—å ‚Äî —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        positive_words = {"great", "excellent", "perfect", "amazing", "thank", "good", "fast", "professional"}
        negative_words = {"bad", "terrible", "slow", "wrong", "disappointed", "error", "mistake", "poor"}

        words = set(text.lower().split())
        pos_count = len(words & positive_words)
        neg_count = len(words & negative_words)

        if pos_count > neg_count:
            score = min(1.0, 0.5 + 0.1 * pos_count)
            label = "positive"
        elif neg_count > pos_count:
            score = max(0.0, 0.5 - 0.1 * neg_count)
            label = "negative"
        else:
            score = 0.5
            label = "neutral"

        # –ü—Ä–æ—Å—Ç–æ–π –∫–ª—é—á–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑
        keywords = [w for w in words if len(w) > 4][:5]

        return {
            "score": score,
            "label": label,
            "keywords": keywords
        }

    def _calculate_success_score(self, signals: Dict[str, Any]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —É—Å–ø–µ—Ö–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–≥–Ω–∞–ª–æ–≤."""
        score = 0.0
        weight = 0

        # –†–µ–π—Ç–∏–Ω–≥ (–º–∞–∫—Å. 0.4)
        if signals.get("explicit_rating") is not None:
            score += (signals["explicit_rating"] / 5.0) * 0.4
            weight += 0.4

        # –°–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç—å (0.2)
        if signals.get("on_time_delivery"):
            score += 0.2
            weight += 0.2

        # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–∫–∞–∑ (0.2)
        if signals.get("reordered"):
            score += 0.2
            weight += 0.2

        # –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (0.2)
        score += signals.get("sentiment_score", 0.5) * 0.2
        weight += 0.2

        # –®—Ç—Ä–∞—Ñ –∑–∞ —Ä–µ–≤–∏–∑–∏–∏
        revisions = signals.get("revision_count", 0)
        if revisions > 2:
            score *= max(0.5, 1.0 - (revisions - 2) * 0.1)

        return min(1.0, max(0.0, score / weight if weight > 0 else 0.5))

    def _persist_analysis(self, feedback_id: str, analysis: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É."""
        try:
            filepath = self.data_dir / f"{feedback_id}.json"
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
            logger.debug(f"üíæ Saved feedback analysis to {filepath}")
        except Exception as e:
            logger.error(f"üí• Failed to persist feedback analysis: {e}")
            raise

    def _update_knowledge_base(self, analysis: Dict[str, Any]) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞."""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å –¥–ª—è KB
            kb_entry = {
                "type": "feedback_insight",
                "source": "feedback_analyzer",
                "timestamp": analysis["timestamp"],
                "job_id": analysis["job_id"],
                "client_id": analysis["client_id"],
                "success_score": analysis["success_score"],
                "sentiment": analysis.get("sentiment_label"),
                "keywords": analysis.get("keywords", []),
                "patterns": analysis.get("dialogue_patterns", {}),
                "lessons": self._generate_lessons(analysis)
            }

            self.knowledge_base.add_entry(kb_entry)
            logger.debug("üß† KnowledgeBase updated with new feedback insight.")
        except Exception as e:
            logger.error(f"üí• Failed to update KnowledgeBase: {e}")

    def _generate_lessons(self, analysis: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤—ã–≤–æ–¥—ã ('—É—Ä–æ–∫–∏') –∏–∑ –∞–Ω–∞–ª–∏–∑–∞."""
        lessons = []

        if analysis["success_score"] < 0.4:
            lessons.append("–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞ –∫–ª–∏–µ–Ω—Ç–∞ ‚Äî –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–¥—Ö–æ–¥ –∫ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏")
        if analysis.get("revision_count", 0) > 2:
            lessons.append("–ß–∞—Å—Ç—ã–µ –ø—Ä–∞–≤–∫–∏ ‚Äî —É—Ç–æ—á–Ω—è—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ω–∞ —ç—Ç–∞–ø–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è")
        if analysis.get("sentiment_label") == "negative":
            lessons.append("–ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å ‚Äî –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π")
        if analysis.get("reordered"):
            lessons.append("–ö–ª–∏–µ–Ω—Ç –≤–µ—Ä–Ω—É–ª—Å—è ‚Äî –∑–∞–∫—Ä–µ–ø–∏—Ç—å —É—Å–ø–µ—à–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")

        return lessons

    def get_aggregated_insights(self, days: int = 30) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π."""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏—é –ø–æ —Ñ–∞–π–ª–∞–º –≤ data/feedback/
        # –î–ª—è MVP ‚Äî –∑–∞–≥–ª—É—à–∫–∞
        return {
            "period_days": days,
            "total_feedbacks": len(self.processed_feedback_ids),
            "avg_success_score": 0.75,
            "common_issues": ["unclear_requirements", "slow_response"],
            "improvement_suggestions": ["ask_more_questions", "send_intermediate_reports"]
        }