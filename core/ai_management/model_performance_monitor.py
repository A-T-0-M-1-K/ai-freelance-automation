# AI_FREELANCE_AUTOMATION/core/ai_management/model_performance_monitor.py
"""
Model Performance Monitor ‚Äî –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç–æ—á–Ω–æ—Å—Ç—å, –∑–∞–¥–µ—Ä–∂–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–æ—Å—Ç—å AI-–º–æ–¥–µ–ª–µ–π.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å IntelligentMonitoringSystem –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–π –∏ predictive analytics.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç hot-reload –º–µ—Ç—Ä–∏–∫ –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏.
"""

import asyncio
import logging
import time
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã (–±–µ–∑ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
from core.config.unified_config_manager import UnifiedConfigManager
from core.monitoring.intelligent_monitoring_system import IntelligentMonitoringSystem
from core.security.audit_logger import AuditLogger


@dataclass
class ModelMetrics:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏."""
    model_id: str
    timestamp: datetime
    inference_time_sec: float
    memory_usage_mb: float
    cpu_usage_percent: float
    accuracy_score: Optional[float] = None
    token_per_sec: Optional[float] = None
    error_count: int = 0
    success_count: int = 0
    input_tokens: Optional[int] = None
    output_tokens: Optional[int] = None


class ModelPerformanceMonitor:
    """
    –ú–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ AI-–º–æ–¥–µ–ª–µ–π.
    –°–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏, –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é,
    –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ —Ç—Ä–∏–≥–≥–µ—Ä–∏—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é.
    """

    def __init__(
        self,
        config_manager: UnifiedConfigManager,
        monitoring_system: IntelligentMonitoringSystem,
        audit_logger: Optional[AuditLogger] = None
    ):
        self.config = config_manager.get_section("ai_management")
        self.monitoring_system = monitoring_system
        self.audit_logger = audit_logger or AuditLogger()
        self.logger = logging.getLogger("ModelPerformanceMonitor")

        # –í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self._metrics_buffer: Dict[str, List[ModelMetrics]] = {}
        self._running = False
        self._collection_interval = self.config.get("performance_collection_interval_sec", 30)
        self._retention_window = timedelta(hours=self.config.get("metrics_retention_hours", 24))

        self.logger.info("Intialized ModelPerformanceMonitor with interval=%ds", self._collection_interval)

    async def start(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫."""
        if self._running:
            self.logger.warning("ModelPerformanceMonitor —É–∂–µ –∑–∞–ø—É—â–µ–Ω.")
            return
        self._running = True
        self.logger.info("üü¢ –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π...")
        asyncio.create_task(self._metrics_collection_loop())

    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        self._running = False
        self.logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ ModelPerformanceMonitor.")

    async def _metrics_collection_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–±–æ—Ä–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –º–µ—Ç—Ä–∏–∫."""
        while self._running:
            try:
                await self._collect_and_send_metrics()
                await asyncio.sleep(self._collection_interval)
            except Exception as e:
                self.logger.error("‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫: %s", e, exc_info=True)
                await self.audit_logger.log_security_event(
                    event_type="monitoring_failure",
                    details={"error": str(e), "component": "ModelPerformanceMonitor"}
                )

    async def _collect_and_send_metrics(self):
        """–°–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –±—É—Ñ–µ—Ä–∞, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥."""
        now = datetime.utcnow()
        for model_id in list(self._metrics_buffer.keys()):
            # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏
            self._metrics_buffer[model_id] = [
                m for m in self._metrics_buffer[model_id]
                if now - m.timestamp <= self._retention_window
            ]
            if not self._metrics_buffer[model_id]:
                del self._metrics_buffer[model_id]
                continue

            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            recent = self._metrics_buffer[model_id][-10:]  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π
            avg_inference = sum(m.inference_time_sec for m in recent) / len(recent)
            avg_memory = sum(m.memory_usage_mb for m in recent) / len(recent)
            total_success = sum(m.success_count for m in recent)
            total_errors = sum(m.error_count for m in recent)
            error_rate = total_errors / (total_success + total_errors + 1e-8)

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
            metric_payload = {
                "model_id": model_id,
                "avg_inference_time_sec": avg_inference,
                "avg_memory_usage_mb": avg_memory,
                "error_rate": error_rate,
                "throughput_tps": sum(m.token_per_sec or 0 for m in recent) / len(recent),
                "last_updated": now.isoformat()
            }

            await self.monitoring_system.submit_metric(
                source="ai_model",
                metric_name=f"model.{model_id}.performance",
                value=metric_payload
            )

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–µ–∑–∫–∏–π —Ä–æ—Å—Ç latency)
            if len(recent) >= 5:
                baseline = sum(m.inference_time_sec for m in recent[:-1]) / (len(recent) - 1)
                current = recent[-1].inference_time_sec
                if current > baseline * 2.0:  # +100% ‚Äî –∞–Ω–æ–º–∞–ª–∏—è
                    await self.monitoring_system.trigger_alert(
                        severity="warning",
                        message=f"–ê–Ω–æ–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç latency —É –º–æ–¥–µ–ª–∏ {model_id}: {current:.2f}s (baseline: {baseline:.2f}s)",
                        context={"model_id": model_id, "metric": "inference_time"}
                    )

    def record_inference(
        self,
        model_id: str,
        inference_time_sec: float,
        memory_usage_mb: float,
        cpu_usage_percent: float,
        success: bool = True,
        accuracy_score: Optional[float] = None,
        input_tokens: Optional[int] = None,
        output_tokens: Optional[int] = None,
    ):
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–¥–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –º–æ–¥–µ–ª–∏.
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ inference_engine –∏–ª–∏ model_manager –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.
        """
        if not self._running:
            return  # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–µ –∑–∞–ø—É—â–µ–Ω

        metrics = ModelMetrics(
            model_id=model_id,
            timestamp=datetime.utcnow(),
            inference_time_sec=inference_time_sec,
            memory_usage_mb=memory_usage_mb,
            cpu_usage_percent=cpu_usage_percent,
            accuracy_score=accuracy_score,
            token_per_sec=(
                (output_tokens or 0) / inference_time_sec
                if inference_time_sec > 0 else 0
            ),
            success_count=int(success),
            error_count=int(not success),
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )

        if model_id not in self._metrics_buffer:
            self._metrics_buffer[model_id] = []
        self._metrics_buffer[model_id].append(metrics)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π
        if not success:
            self.logger.warning("‚ö†Ô∏è –ù–µ—É–¥–∞—á–Ω—ã–π –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ %s", model_id)
        elif inference_time_sec > self.config.get("max_inference_time_sec", 30):
            self.logger.warning("üê¢ –ú–µ–¥–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ %s: %.2fs", model_id, inference_time_sec)

    def get_recent_metrics(self, model_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π –º–µ—Ç—Ä–∏–∫ –¥–ª—è –º–æ–¥–µ–ª–∏ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏/API)."""
        records = self._metrics_buffer.get(model_id, [])
        return [asdict(r) for r in records[-limit:]]

    def clear_metrics(self, model_id: Optional[str] = None):
        """–û—á–∏—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ (–¥–ª—è —Ç–µ—Å—Ç–æ–≤ –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏)."""
        if model_id:
            self._metrics_buffer.pop(model_id, None)
        else:
            self._metrics_buffer.clear()
        self.logger.info("üßπ –û—á–∏—â–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ %s", model_id or "–≤—Å–µ—Ö")