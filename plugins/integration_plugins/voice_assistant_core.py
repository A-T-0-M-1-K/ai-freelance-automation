import asyncio
import json
import re
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import torch
from transformers import pipeline, WhisperProcessor, WhisperForConditionalGeneration
from core.communication.context_manager import ContextManager
from core.communication.multilingual_support import MultilingualSupport
from services.ai_services.voice_cloning_service import VoiceCloningService
from core.ai_management.lazy_model_loader import LazyModelLoader


class VoiceAssistantCore:
    """
    –Ø–¥—Ä–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
    - –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (Whisper)
    - –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏–π
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏ —Ñ—Ä–∏–ª–∞–Ω—Å–∞ –≥–æ–ª–æ—Å–æ–º
    - –ì–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç—á—ë—Ç–æ–≤ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞
    - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —É–º–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ (–Ø–Ω–¥–µ–∫—Å.–°—Ç–∞–Ω—Ü–∏—è, Google Home)
    """

    def __init__(self, config: Dict):
        self.config = config
        self.context_manager = ContextManager()
        self.multilingual = MultilingualSupport()
        self.voice_cloner = VoiceCloningService()
        self.loader = LazyModelLoader.get_instance()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (–ª–µ–Ω–∏–≤–∞—è)
        self.whisper_model = None
        self.whisper_processor = None
        self.intent_classifier = None

        self.active_sessions: Dict[str, Dict] = {}  # session_id -> {user_id, context, last_interaction}
        self.voice_profiles: Dict[str, Dict] = {}  # user_id -> {voice_embedding, preferences}

        self._initialize_models()

    def _initialize_models(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏"""
        # –ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤
        pass

    async def transcribe_audio(self, audio_bytes: bytes, language: str = "ru") -> str:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é Whisper.
        """
        # –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        if self.whisper_model is None:
            print("üîä –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏...")
            model_name = self.config.get("whisper_model", "openai/whisper-medium")

            self.whisper_processor = await self.loader.load_model_async(
                model_name,
                model_class=WhisperProcessor,
                subfolder="processor"
            )

            self.whisper_model = await self.loader.load_model_async(
                model_name,
                model_class=WhisperForConditionalGeneration,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else "cpu"
            )

            print("‚úÖ –ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Whisper
        import io
        from pydub import AudioSegment

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ 16kHz –º–æ–Ω–æ PCM
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio_np = audio.get_array_of_samples()

        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
        inputs = self.whisper_processor(audio_np, sampling_rate=16000, return_tensors="pt")

        if torch.cuda.is_available():
            inputs = {k: v.cuda() for k, v in inputs.items()}

        with torch.no_grad():
            predicted_ids = self.whisper_model.generate(**inputs)

        transcription = self.whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        self._log_transcription(audio_bytes, transcription, language)

        return transcription.strip()

    async def understand_intent(self, text: str, user_id: str, session_id: str) -> Dict:
        """
        –ü–æ–Ω–∏–º–∞–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ —Ç–µ–∫—Å—Ç–∞.

        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è:
        - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏: "–∑–∞–ø—É—Å—Ç–∏ –∑–∞–¥–∞—á—É –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ –ò–≤–∞–Ω–∞", "–ø–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞ #123"
        - –§–∏–Ω–∞–Ω—Å—ã: "–∫–∞–∫–æ–π –º–æ–π –¥–æ—Ö–æ–¥ –∑–∞ –Ω–µ–¥–µ–ª—é?", "—Å–æ–∑–¥–∞–π —Å—á—ë—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞"
        - –ê–Ω–∞–ª–∏—Ç–∏–∫–∞: "–∫–∞–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –º–µ—Å—è—Ü?", "–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–π —Ç—Ä–µ–Ω–¥—ã –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –Ω–µ–¥–µ–ª—é"
        - –ü–æ—Ä—Ç—Ñ–æ–ª–∏–æ: "–æ–±–Ω–æ–≤–∏ –º–æ—ë –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ", "—Å–æ–∑–¥–∞–π –¥–µ–º–æ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞"
        - –°–∏—Å—Ç–µ–º–Ω—ã–µ: "–Ω–∞—Å—Ç—Ä–æ–π —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è", "–ø—Ä–æ–≤–µ—Ä—å –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã"
        """
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–π (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –ø—Ä–∞–≤–∏–ª–∞)
        if self.intent_classifier is None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ + —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –Ω–∞—á–∞–ª–∞
            # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ fine-tuned BERT –º–æ–¥–µ–ª—å
            self.intent_classifier = self._build_rule_based_classifier()

        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
        context = self.context_manager.get_context(user_id, session_id)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        intent = self._classify_intent_with_context(text, context)

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π (–∫–ª–∏–µ–Ω—Ç—ã, –∑–∞–∫–∞–∑—ã, –¥–∞—Ç—ã)
        entities = self._extract_entities(text, context)

        # –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        self.context_manager.update_context(
            user_id=user_id,
            session_id=session_id,
            new_input=text,
            intent=intent,
            entities=entities
        )

        return {
            "intent": intent,
            "entities": entities,
            "confidence": 0.9,  # –î–ª—è –ø—Ä–∞–≤–∏–ª–∞-based; –¥–ª—è ML –º–æ–¥–µ–ª–∏ ‚Äî —Ä–µ–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä
            "context": context,
            "suggested_actions": self._get_suggested_actions(intent, entities)
        }

    def _classify_intent_with_context(self, text: str, context: Dict) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        text_lower = text.lower()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –Ω–∞–º–µ—Ä–µ–Ω–∏–π (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞)
        if context.get("last_intent") == "ask_job_status" and any(
                word in text_lower for word in ["–¥–∞", "–∫–æ–Ω–µ—á–Ω–æ", "–ø–æ–∫–∞–∂–∏"]):
            return "show_job_details"

        # –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        intent_patterns = {
            "start_task": [
                r"–∑–∞–ø—É—Å—Ç–∏ –∑–∞–¥–∞—á—É", r"–Ω–∞—á–Ω–∏ —Ä–∞–±–æ—Ç—É", r"–≤—ã–ø–æ–ª–Ω–∏ –∑–∞–∫–∞–∑",
                r"–æ–±—Ä–∞–±–æ—Ç–∞–π –∑–∞–¥–∞—á—É", r"–∑–∞–ø—É—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫—É"
            ],
            "check_job_status": [
                r"—Å—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞", r"–∫–∞–∫ –¥–µ–ª–∞ —Å –∑–∞–∫–∞–∑–æ–º", r"–ø—Ä–æ–≤–µ—Ä—å –∑–∞–¥–∞—á—É",
                r"–≥–¥–µ –º–æ–π –∑–∞–∫–∞–∑", r"—Ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
            ],
            "financial_report": [
                r"–¥–æ—Ö–æ–¥ –∑–∞", r"—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞", r"—Ñ–∏–Ω–∞–Ω—Å—ã –∑–∞", r"—Å–∫–æ–ª—å–∫–æ –∑–∞—Ä–∞–±–æ—Ç–∞–ª",
                r"–æ—Ç—á—ë—Ç –ø–æ –¥–æ—Ö–æ–¥–∞–º", r"—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á—ë—Ç"
            ],
            "market_analysis": [
                r"—Ç—Ä–µ–Ω–¥—ã", r"–ø—Ä–æ–≥–Ω–æ–∑", r"–∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞", r"—á—Ç–æ –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–æ",
                r"–∫–∞–∫–∏–µ –Ω–∞–≤—ã–∫–∏", r"—Ä—ã–Ω–æ—á–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞"
            ],
            "portfolio_update": [
                r"–æ–±–Ω–æ–≤–∏ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ", r"—Å–æ–∑–¥–∞–π –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ", r"–ø–æ–∫–∞–∂–∏ –º–æ–∏ —Ä–∞–±–æ—Ç—ã",
                r"–¥–µ–º–æ –ø—Ä–æ–µ–∫—Ç–∞", r"–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –¥–µ–º–æ"
            ],
            "system_health": [
                r"–∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã", r"–ø—Ä–æ–≤–µ—Ä—å —Å–∏—Å—Ç–µ–º—É", r"–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
                r"—Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–æ–≤", r"–µ—Å—Ç—å –ª–∏ –æ—à–∏–±–∫–∏"
            ],
            "client_management": [
                r"–∫–ª–∏–µ–Ω—Ç", r"–∑–∞–∫–∞–∑—á–∏–∫", r"–ø–æ–∫–∞–∂–∏ –∫–ª–∏–µ–Ω—Ç–∞", r"–∏—Å—Ç–æ—Ä–∏—è –∫–ª–∏–µ–Ω—Ç–∞"
            ],
            "voice_report": [
                r"–≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç—á—ë—Ç", r"–æ–∑–≤—É—á–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É", r"—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ",
                r"–ø—Ä–æ—á–∏—Ç–∞–π –æ—Ç—á—ë—Ç", r"–∞—É–¥–∏–æ –æ—Ç—á—ë—Ç"
            ]
        }

        for intent, patterns in intent_patterns.items():
            if any(re.search(pattern, text_lower) for pattern in patterns):
                return intent

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        return "search_information"

    def _extract_entities(self, text: str, context: Dict) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        entities = {}
        text_lower = text.lower()

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –∑–∞–∫–∞–∑–∞ (#123 –∏–ª–∏ –∑–∞–∫–∞–∑ 123)
        order_match = re.search(r"#(\d+)|–∑–∞–∫–∞–∑\s+(\d+)", text_lower)
        if order_match:
            entities["job_id"] = order_match.group(1) or order_match.group(2)

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞
        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥ ‚Äî –ø–æ–∏—Å–∫ –≤ —Å–ø–∏—Å–∫–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
        known_clients = self._get_known_clients()
        for client in known_clients:
            if client.lower() in text_lower:
                entities["client_name"] = client
                break

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞ –≤—Ä–µ–º–µ–Ω–∏
        time_periods = {
            "–Ω–µ–¥–µ–ª—è": "week",
            "–º–µ—Å—è—Ü": "month",
            "–¥–µ–Ω—å": "day",
            "–≥–æ–¥": "year",
            "—Å–µ–≥–æ–¥–Ω—è": "today",
            "–≤—á–µ—Ä–∞": "yesterday"
        }

        for ru_period, en_period in time_periods.items():
            if ru_period in text_lower:
                entities["time_period"] = en_period
                break

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–µ—Å–ª–∏ —Å—É—â–Ω–æ—Å—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞ —è–≤–Ω–æ)
        if "job_id" not in entities and context.get("last_job_id"):
            entities["job_id"] = context["last_job_id"]

        if "client_name" not in entities and context.get("last_client"):
            entities["client_name"] = context["last_client"]

        return entities

    def _get_known_clients(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            clients_index = json.loads(Path("data/clients/clients_index.json").read_text())
            return [client["name"] for client in clients_index.get("clients", [])]
        except:
            return ["–ò–≤–∞–Ω", "–ú–∞—Ä–∏—è", "–ê–ª–µ–∫—Å–µ–π", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞"]  # –§–æ–ª–±—ç–∫

    def _get_suggested_actions(self, intent: str, entities: Dict) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"""
        suggestions = {
            "start_task": [
                "–ù–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∑–∞–∫–∞–∑—ã –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö",
                "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∑–∞–∫–∞–∑–∞",
                "–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞"
            ],
            "check_job_status": [
                "–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –∑–∞–∫–∞–∑–∞",
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ä–æ–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
                "–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∫–ª–∏–µ–Ω—Ç—É"
            ],
            "financial_report": [
                "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç",
                "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ Excel",
                "–ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –¥–æ—Ö–æ–¥–æ–≤"
            ],
            "market_analysis": [
                "–ü–æ–∫–∞–∑–∞—Ç—å —Ç—Ä–µ–Ω–¥—ã –ø–æ –Ω–∞–≤—ã–∫–∞–º",
                "–°—Ä–∞–≤–Ω–∏—Ç—å —Å –ø—Ä–æ—à–ª—ã–º –ø–µ—Ä–∏–æ–¥–æ–º",
                "–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è"
            ]
        }

        return suggestions.get(intent, ["–í—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ", "–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏", "–û—Ç–º–µ–Ω–∏—Ç—å"])

    async def execute_voice_command(self, intent: str, entities: Dict, user_id: str) -> Dict:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è.
        """
        result = {
            "status": "success",
            "message": "",
            "data": None,
            "audio_response": None  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç
        }

        try:
            if intent == "start_task":
                job_id = entities.get("job_id") or self._find_most_relevant_job(user_id)
                if job_id:
                    # –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
                    from core.automation.task_orchestrator import TaskOrchestrator
                    orchestrator = TaskOrchestrator.get_instance()
                    await orchestrator.start_job_execution(job_id, user_id)

                    result["message"] = f"–ó–∞–¥–∞—á–∞ –¥–ª—è –∑–∞–∫–∞–∑–∞ #{job_id} –∑–∞–ø—É—â–µ–Ω–∞"
                    result["data"] = {"job_id": job_id, "status": "in_progress"}

            elif intent == "check_job_status":
                job_id = entities.get("job_id")
                if job_id:
                    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–∫–∞–∑–∞
                    job_details = self._get_job_details(job_id)
                    result["message"] = f"–°—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞ #{job_id}: {job_details.get('status', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}"
                    result["data"] = job_details

            elif intent == "financial_report":
                period = entities.get("time_period", "week")
                report = await self._generate_financial_report(user_id, period)
                result["message"] = f"–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á—ë—Ç –∑–∞ {period}: {report['summary']}"
                result["data"] = report

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ
                if entities.get("voice_report", False) or "–æ–∑–≤—É—á" in entities.get("original_text", ""):
                    result["audio_response"] = await self._generate_voice_report(report, user_id)

            elif intent == "voice_report":
                # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç—á—ë—Ç
                period = entities.get("time_period", "week")
                report = await self._generate_financial_report(user_id, period)
                audio = await self._generate_voice_report(report, user_id)

                result["message"] = "–ì–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω"
                result["audio_response"] = audio
                result["data"] = {"report_summary": report["summary"], "audio_duration_sec": len(audio) / 16000}

            # ... –¥—Ä—É–≥–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è

            else:
                result["status"] = "unknown_intent"
                result[
                    "message"] = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ: {intent}. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã: –∑–∞–ø—É—Å—Ç–∏ –∑–∞–¥–∞—á—É, —Å—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞, –æ—Ç—á—ë—Ç –∑–∞ –Ω–µ–¥–µ–ª—é"

        except Exception as e:
            result["status"] = "error"
            result["message"] = f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {str(e)}"
            import traceback
            print(f"–û—à–∏–±–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã: {traceback.format_exc()}")

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        self._log_command_execution(user_id, intent, entities, result)

        return result

    async def _generate_voice_report(self, report_data: Dict, user_id: str) -> bytes:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ-–æ—Ç—á—ë—Ç–∞ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –æ—Ç—á—ë—Ç–∞
        report_text = self._format_report_text(report_data)

        # –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º
        audio_bytes = await self.voice_cloner.synthesize_speech(
            text=report_text,
            speaker_id=user_id,
            language="ru",
            emotion="neutral",
            speed=1.0
        )

        return audio_bytes

    def _format_report_text(self, report: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç—á—ë—Ç–∞ –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏"""
        summary = report.get("summary", {})
        period = report.get("period", "–Ω–µ–¥–µ–ª—è")

        # –ü—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        text = f"–í–∞—à —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á—ë—Ç –∑–∞ {period}. "
        text += f"–û–±—â–∏–π –¥–æ—Ö–æ–¥: {summary.get('total_income', 0):.0f} —Ä—É–±–ª–µ–π. "
        text += f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤: {summary.get('completed_jobs', 0)}. "
        text += f"–°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {summary.get('average_check', 0):.0f} —Ä—É–±–ª–µ–π. "
        text += "–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!"

        return text

    def _find_most_relevant_job(self, user_id: str) -> Optional[str]:
        """–ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∑–∞–∫–∞–∑–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)"""
        # –õ–æ–≥–∏–∫–∞ –ø–æ–∏—Å–∫–∞: –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–∫–∞–∑, –∑–∞–∫–∞–∑ —Å –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–º—Å—è –¥–µ–¥–ª–∞–π–Ω–æ–º –∏ —Ç.–¥.
        try:
            jobs_index = json.loads(Path("data/jobs/jobs_index.json").read_text())
            active_jobs = [
                job for job in jobs_index.get("jobs", [])
                if job.get("status") in ["in_progress", "revision"]
            ]

            if active_jobs:
                # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (—Å–∞–º—ã–π —Å–≤–µ–∂–∏–π ‚Äî –ø–µ—Ä–≤—ã–π)
                active_jobs.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
                return active_jobs[0].get("job_id")
        except:
            pass

        return None

    def _get_job_details(self, job_id: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –∑–∞–∫–∞–∑–∞"""
        try:
            job_file = Path(f"data/jobs/{job_id}/job_details.json")
            if job_file.exists():
                return json.loads(job_file.read_text())
        except:
            pass

        return {"job_id": job_id, "status": "not_found", "error": "–ó–∞–∫–∞–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω"}

    async def _generate_financial_report(self, user_id: str, period: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        # –ò–º–ø–æ—Ä—Ç –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        from core.analytics.market_analyzer import MarketAnalyzer

        analyzer = MarketAnalyzer.get_instance()
        report = await analyzer.generate_financial_report(user_id, period)

        return report

    def _log_transcription(self, audio: bytes, text: str, language: str):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "language": language,
            "text": text,
            "audio_hash": hash(audio)  # –£–ø—Ä–æ—â—ë–Ω–Ω–æ; –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ ‚Äî SHA256
        }

        log_file = Path("data/logs/voice_transcriptions.jsonl")
        log_file.parent.mkdir(parents=True, exist_ok=True)

        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')

    def _log_command_execution(self, user_id: str, intent: str, entities: Dict, result: Dict):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "user_id": user_id,
            "intent": intent,
            "entities": entities,
            "result_status": result["status"],
            "processing_time_ms": result.get("processing_time", 0)
        }

        log_file = Path("data/logs/voice_commands.jsonl")
        log_file.parent.mkdir(parents=True, exist_ok=True)

        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')

    def register_voice_profile(self, user_id: str, audio_sample: bytes, preferences: Dict = None):
        """
        –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏.
        """
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ ‚Äî —á–µ—Ä–µ–∑ speaker embedding –º–æ–¥–µ–ª—å)
        voice_hash = hash(audio_sample)  # –£–ø—Ä–æ—â—ë–Ω–Ω–æ

        self.voice_profiles[user_id] = {
            "voice_hash": voice_hash,
            "registered_at": datetime.utcnow().isoformat(),
            "preferences": preferences or {},
            "sample_count": 1
        }

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –¥–∏—Å–∫
        profiles_file = Path("data/voice_profiles.json")
        profiles = {}

        if profiles_file.exists():
            try:
                profiles = json.loads(profiles_file.read_text())
            except:
                pass

        profiles[user_id] = self.voice_profiles[user_id]

        with open(profiles_file, 'w', encoding='utf-8') as f:
            json.dump(profiles, f, indent=2, ensure_ascii=False)

        print(f"‚úÖ –ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")

    async def handle_conversational_dialog(self, session_id: str, user_utterance: str, user_id: str) -> Dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–≥–æ—Ö–æ–¥–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        """
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = {
                "user_id": user_id,
                "created_at": datetime.utcnow(),
                "last_interaction": datetime.utcnow(),
                "dialog_history": []
            }

        session = self.active_sessions[session_id]
        session["last_interaction"] = datetime.utcnow()

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–ø–ª–∏–∫–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é
        session["dialog_history"].append({
            "role": "user",
            "text": user_utterance,
            "timestamp": datetime.utcnow().isoformat()
        })

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        intent_result = await self.understand_intent(user_utterance, user_id, session_id)

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã
        execution_result = await self.execute_voice_command(
            intent_result["intent"],
            intent_result["entities"],
            user_id
        )

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        assistant_response = self._generate_assistant_response(intent_result, execution_result)

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        session["dialog_history"].append({
            "role": "assistant",
            "text": assistant_response,
            "timestamp": datetime.utcnow().isoformat()
        })

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å–µ—Å—Å–∏–π (> 1 —á–∞—Å –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
        await self._cleanup_inactive_sessions()

        return {
            "response_text": assistant_response,
            "intent": intent_result["intent"],
            "entities": intent_result["entities"],
            "audio_response": execution_result.get("audio_response"),
            "suggested_actions": intent_result["suggested_actions"]
        }

    def _generate_assistant_response(self, intent_result: Dict, execution_result: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
        intent = intent_result["intent"]
        status = execution_result["status"]

        responses = {
            "start_task": {
                "success": "–ó–∞–¥–∞—á–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–∞. –Ø –Ω–∞—á–Ω—É —Ä–∞–±–æ—Ç—É –Ω–∞–¥ –∑–∞–∫–∞–∑–æ–º.",
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."
            },
            "check_job_status": {
                "success": f"–°—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞: {execution_result.get('data', {}).get('status', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}",
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞."
            },
            "financial_report": {
                "success": "–í–æ—Ç –≤–∞—à —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á—ë—Ç. –î–æ—Ö–æ–¥—ã —Ä–∞—Å—Ç—É—Ç!",
                "error": "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞."
            }
        }

        default_responses = {
            "success": "–ö–æ–º–∞–Ω–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.",
            "error": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã.",
            "unknown_intent": "–Ø –Ω–µ –ø–æ–Ω—è–ª–∞ –∫–æ–º–∞–Ω–¥—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–∞–∑–∞—Ç—å: '–ö–∞–∫–æ–π —Å—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞?' –∏–ª–∏ '–ü–æ–∫–∞–∂–∏ –¥–æ—Ö–æ–¥—ã –∑–∞ –Ω–µ–¥–µ–ª—é'"
        }

        return responses.get(intent, default_responses).get(status, default_responses.get(status, "–ì–æ—Ç–æ–≤–æ"))

    async def _cleanup_inactive_sessions(self, max_inactivity_minutes: int = 60):
        """–û—á–∏—Å—Ç–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π –¥–∏–∞–ª–æ–≥–∞"""
        now = datetime.utcnow()
        to_remove = []

        for session_id, session in self.active_sessions.items():
            last_interaction = session["last_interaction"]
            if isinstance(last_interaction, str):
                last_interaction = datetime.fromisoformat(last_interaction)

            if (now - last_interaction).total_seconds() / 60 > max_inactivity_minutes:
                to_remove.append(session_id)

        for session_id in to_remove:
            del self.active_sessions[session_id]

        if to_remove:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {len(to_remove)} –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–µ—Å—Å–∏–π")


# –ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å WebSocket
async def websocket_voice_handler(websocket, session_id: str, user_id: str):
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ WebSocket –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
    """
    assistant = VoiceAssistantCore(config={})

    while True:
        try:
            message = await websocket.receive_json()
            message_type = message.get("type")

            if message_type == "audio_chunk":
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ-—á–∞–Ω–∫–∞
                audio_bytes = message["audio"]  # base64 –∏–ª–∏ –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                transcription = await assistant.transcribe_audio(audio_bytes)

                await websocket.send_json({
                    "type": "transcription",
                    "text": transcription
                })

            elif message_type == "voice_command":
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã (—É–∂–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π)
                text = message["text"]
                result = await assistant.handle_conversational_dialog(
                    session_id=session_id,
                    user_utterance=text,
                    user_id=user_id
                )

                response = {
                    "type": "assistant_response",
                    "text": result["response_text"],
                    "intent": result["intent"],
                    "actions": result["suggested_actions"]
                }

                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
                if result.get("audio_response"):
                    import base64
                    response["audio"] = base64.b64encode(result["audio_response"]).decode()
                    response["audio_format"] = "wav"

                await websocket.send_json(response)

            elif message_type == "register_voice":
                # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è
                audio_sample = message["audio_sample"]
                assistant.register_voice_profile(user_id, audio_sample, message.get("preferences", {}))

                await websocket.send_json({
                    "type": "voice_registered",
                    "status": "success"
                })

        except Exception as e:
            await websocket.send_json({
                "type": "error",
                "message": str(e)
            })
            break